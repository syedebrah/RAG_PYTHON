{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3cc47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Document Structure\n",
    "\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3116b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=Document(\n",
    "    page_content=\"this is the main text content I am using to create RAG\",\n",
    "    metadata={\n",
    "        \"source\":\"exmaple.txt\",\n",
    "        \"pages\":1,\n",
    "        \"author\":\"syed\",\n",
    "        \"date_created\":\"2025-01-01\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a88706a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'exmaple.txt',\n",
       " 'pages': 1,\n",
       " 'author': 'syed',\n",
       " 'date_created': '2025-01-01'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3c116d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'exmaple.txt', 'pages': 1, 'author': 'syed', 'date_created': '2025-01-01'}, page_content='this is the main text content I am using to create RAG')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "469cc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a simple txt file\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4a7ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts={\n",
    "    \"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"✅ Sample text files created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05123db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "### TextLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader=TextLoader(\"../data/text_files/python_intro.txt\",encoding=\"utf-8\")\n",
    "document=loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7a4b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1654.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/text_files\", #3parent\n",
    "    glob=\"**/*.txt\", ## Pattern to match files  \n",
    "    loader_cls= TextLoader, ##loader class to use\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=True\n",
    "\n",
    ")\n",
    "\n",
    "documents=dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e5c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PDF Loader\n",
    "from langchain_community.document_loaders import PyPDFLoader,PyMuPDFLoader\n",
    "#PyMuPDFLoader is better compared to PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee90ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 0}, page_content=\"1 \\nMachine Learning Operations \\nUNIT I \\nTwo Stages of ML \\nThe typical machine learning (ML) development process can be broken down into two \\nprimary stages: \\n1. Data Preparation and Model Training: \\no Data Collection and Preparation: Gathering relevant data, cleaning it, and \\ntransforming it into a suitable format for model training. \\no Model Selection and Training: Choosing an appropriate ML algorithm and \\ntraining it on the prepared data to learn patterns. \\n2. Model Evaluation and Deployment: \\no Model Evaluation: Assessing the model's performance on a separate dataset to \\nunderstand its accuracy and reliability. \\no Model Deployment: Integrating the trained model into a production \\nenvironment to make predictions or decisions. \\nML in Google Products \\nGoogle is a pioneer in applying ML to its products. Some prominent examples include: \\n• \\nSearch Engine: Understanding search queries, ranking results, and providing relevant \\ninformation. \\n• \\nGoogle Photos: Image recognition, object detection, and organization based on content. \\n• \\nGoogle Translate: Real-time language translation using neural machine translation. \\n• \\nGmail: Spam filtering, smart reply, and priority inbox features. \\n• \\nGoogle Assistant: Natural language understanding, speech recognition, and task \\ncompletion. \\n \\nDialogflow \\nDialogflow (formerly known as Api.ai), is the platform owned by Google to build \\nconversational agents.  \\nInstead of building a chatbot from scratch, Dialogflow makes it easier to build it in considerably \\nless time and with bunch of Google features, including pre-build ML Models that can help you \\nget started right away. Dialogflow also allows you to integrate your conversational agent with \\npopular platforms like Google Assistant, Facebook Messenger, Twitter, Telegram and more. It \\nalso provides Web API to integrate the agent into Websites. \\nAccessing Dialogflow Console: \\n1) Visit https://dialogflow.com.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 1}, page_content='2 \\nMachine Learning Operations \\n \\n2) Sign-in using your Google Account and allow the access to Dialogflow.  \\n \\n3) Access the console by clicking Go to console button in the top-right corner.  \\n \\n \\nGetting familiar with Dialogflow Console:  \\n \\n \\nAgents \\nEvery Conversational Chatbot you make using Dialogflow are called Agents. In the Console \\nyou can see all your agents in the top-left corner where you can configure the agent settings by \\nclicking Gear icon next to your agent name.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 2}, page_content='3 \\nMachine Learning Operations \\n \\nSections in Agent Settings: \\n• \\nGeneral: Here you can configure your Agent name, timezone and delete the agent. \\n• \\nExport/Import: In this section you can backup and restore your Agents (It is good \\npractice to Export your Agent periodically).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 3}, page_content='4 \\nMachine Learning Operations \\nIntents \\n \\nIntents comprises of what End-User’s intend to say. For every agent, there are intents defined \\nto fulfill End-User’s query. Each intent has a specific purpose. When User types a query, \\nDialogflow matches the particular intent and responds to the User. \\nYou can create an Intent using Create Intent button, or by using the Plus icon next to Intent \\nin the Console Pane. \\nAfter opening an Intent, you enter the Training Phrases. These are the example phrases that \\nUser will say. When User’s query resembles these phrases, Dialogflow will match the Intent. \\nYou need to define few phrases and the built-in Machine Learning will add more phrases over \\nthe time. \\n \\nIn the Responses section of Intent, you provide the statement which is used as the reply to the \\nUser’s Invocation Phrase. You can define multiple replies and Dialogflow will randomly \\nprovide a reply from the given responses.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 4}, page_content='5 \\nMachine Learning Operations \\n \\nOther than Training Phrases and Responses, another powerful feature of Dialogflow is Actions \\nand Parameters. In some intents you would like to obtain a particular data from User’s phrase. \\nYou can define parameters by right-clicking any phrase from the Invocation Phrases list, and \\nselect the Entity-type that suits your requirement. Dialogflow has built-in parameters \\nlike sys.geo-location, sys.date and more. You can even define your own parameters (in the \\nEntities).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 5}, page_content='6 \\nMachine Learning Operations \\nEntities \\nEntities in context of Dialogflow are the set of Keywords that can be extracted as a parameter. \\nYou can define an Entity using Create Entity or the Plus icon next to Entity in the Console \\nPane. \\nHere, each Entry in the Entity holds a specific keyword. These keywords can have several \\nsynonyms. Dialogflow allows you to define synonyms along with the keyword. \\n \\nFor example, if you define an entity “GeographicalFeature” with entry “Water Body” and \\ndefine synonyms as lake, pond, ocean. When user says “I want to visit ocean“. Dialogflow \\nunderstands the reference and extracts the parameter as “Water Body”. \\nEntities are really useful. These extracted parameters can be used to make conversations more \\nhuman-like (using Fulfillment). \\nFulfillment \\nUsing Fulfillment adds more functionality to your agent. You have to enable Fulfillment for \\neach Intent you require. There are two way to use the Fulfillment feature: \\n• \\nWebhook'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 6}, page_content='7 \\nMachine Learning Operations \\nUsing Webhook, you can use externally deployed back-end to fulfill user query. The extracted \\nparameter are packed using JSON. In the Webhook section you just need to provide the URL \\nfor your back-end and during each invocation, Dialogflow will send the user’s query and \\nParameters to the back-end. \\n• \\nInline Editor \\n \\nInline Editor allows you to manage fulfillment directly from the cloud functions. You need to \\nhave \\nunderstanding \\nof \\nNodeJS \\nto \\nuse \\nInline \\nEditor. \\nHere \\nyou \\ncan \\nmodify index.js and package.json according to the requirement of your agent. \\nIntegrations \\nAfter completing your agent, the last part is Integration. Here you can deploy your Agent to \\npopular services like Google Assistant, Facebook Messenger and more. Select the platform to \\ndeploy your agent.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 7}, page_content='8 \\nMachine Learning Operations'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 8}, page_content=\"9 \\nMachine Learning Operations \\n  \\nVision API \\nThe Vision API is a powerful tool that uses machine learning to understand the content \\nof images. It provides developers with a simple interface to access pre-trained models that can \\nextract information from images. \\nHow it works: \\n1. Image Upload: You send an image to the Vision API, either as an image file or an \\nimage URL. \\n2. Image Analysis: The API processes the image using advanced machine learning \\nmodels. \\n3. Response: The API returns information about the image, such as labels, detected \\nobjects, or extracted text. \\nKey Features: \\n• \\nImage Labeling: Identifies objects, places, and actions within an image. \\n• \\nFace Detection: Detects faces within an image and provides information about \\nattributes like emotions, landmarks, and poses. \\n• \\nOptical Character Recognition (OCR): Extracts printed and handwritten text from \\nimages. \\n• \\nLandmark Detection: Identifies famous landmarks within an image. \\n• \\nLogo Detection: Recognizes logos of popular brands. \\n• \\nImage Properties: Provides information about image properties like dominant colors. \\n• \\nSafe Search Detection: Identifies potentially sensitive content within images. \\n \\nGetting Started \\n1. Enable the Vision API: Visit the Google Cloud Platform console, navigate to the API & \\nServices section, and enable the Vision API for your project. \\n2. Set Up Authentication: Create a service account with appropriate permissions and \\ngenerate a key file. \\n3. Choose a Programming Language: The Vision API supports multiple languages, \\nincluding Python, Java, Node.js, and Go. \\n1. Enabling the Google Cloud Vision API \\nTo use the Google Cloud Vision API, you'll need to enable it for your Google Cloud project. \\nHere's a step-by-step guide:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 9}, page_content='10 \\nMachine Learning Operations \\nPrerequisites: \\n• \\nA Google Cloud Platform (GCP) account. \\n• \\nA Google Cloud project with billing enabled. \\nSteps: \\n1. Sign in to the Google Cloud Console: Visit https://console.cloud.google.com/ and sign \\nin with your Google account. \\n2. Select or Create a Project: Choose an existing project or create a new one for your \\nVision API usage. \\n3. Enable the Vision API: \\no Navigate to the APIs & Services section in the console. \\no Search for \"Cloud Vision API\" and select it. \\no Click the Enable button. \\n2. Setting Up Authentication for the Google Cloud Vision API \\nTo use the Google Cloud Vision API, you\\'ll need to authenticate your requests. This ensures \\nthat Google can verify your identity and authorize access to the API. \\nUnderstanding Authentication Methods \\nThere are two primary methods for authenticating with the Google Cloud Vision API: \\n1. Application Default Credentials (ADC): This method is suitable for local \\ndevelopment and testing. It automatically uses the credentials associated with your \\nGoogle account. \\n2. Service Accounts: For production environments and more granular control, service \\naccounts provide a robust authentication mechanism. \\nSetting Up Service Accounts \\n1. Create a Service Account: \\no Go to the Google Cloud Console and navigate to the IAM & Admin section. \\no Select \"Service accounts\" and click \"Create Service Account\". \\no Give your service account a name and description. \\no Grant the necessary roles to the service account. For Vision API, the \"Cloud \\nVision API User\" role is sufficient. \\n2. Create a Key: \\no Select the newly created service account and click the \"Keys\" tab. \\no Click \"Add Key\" and choose \"Create new key\". \\no Select the JSON key type and download the generated JSON file.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 10}, page_content=\"11 \\nMachine Learning Operations \\n3. Store the Key: \\no Securely store the JSON key file. You'll use this file to authenticate your API \\nrequests. \\n3. How to Choose a Programming Language \\nSelecting the right programming language for a project can be a daunting task. Here are some \\nkey factors to consider: \\nUnderstand Your Project Requirements \\n• \\nType of application: Is it a web application, mobile app, desktop software, data \\nanalysis, or something else? \\n• \\nPlatform: Where will the application run (web, mobile, desktop, cloud)? \\n• \\nPerformance requirements: Are there specific speed or efficiency needs? \\n• \\nScalability: Will the application need to handle a large amount of data or users? \\n• \\nSecurity needs: Are there sensitive data or security requirements? \\n• \\nTeam expertise: What languages are your team proficient in? \\nEvaluate Language Features \\n• \\nSyntax and readability: How easy is the language to understand and maintain? \\n• \\nStandard library: Does the language offer built-in functions for common tasks? \\n• \\nEcosystem: Is there a large and active community with libraries and frameworks? \\n• \\nPerformance: How fast is the language for different types of tasks? \\n• \\nCross-platform compatibility: Can the language be used for multiple platforms? \\n• \\nLearning curve: How easy is it to learn the language? \\nPopular Languages and Their Use Cases \\n• \\nPython: Versatile language for data science, machine learning, web development, and \\nscripting. \\n• \\nJavaScript: Primarily used for web development, but also gaining popularity in other \\nareas. \\n• \\nJava: Robust language for enterprise applications, Android app development, and big \\ndata processing. \\n• \\nC++: High-performance language for system programming, game development, and \\nperformance-critical applications. \\n• \\nC#: Used for Windows applications, game development, and web development with \\n.NET. \\n• \\nSwift: Apple's language for iOS app development.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 11}, page_content='12 \\nMachine Learning Operations \\n• \\nKotlin: Modern language for Android app development and multiplatform \\ndevelopment. \\n \\n \\nML training phases \\nThe machine learning lifecycle is a process that guides the development and deployment of \\nmachine learning models in a structured way. It consists of various steps. \\nEach step plays a crucial role in ensuring the success and effectiveness of the machine learning \\nsolution. By following the machine learning lifecycle, organizations can solve complex \\nproblems systematically, leverage data-driven insights, and create scalable and sustainable \\nmachine learning solutions that deliver tangible value. The steps to be followed in the machine \\nlearning lifecycle are: \\n1. Problem Definition \\n2. Data Collection \\n3. Data Cleaning and Preprocessing \\n4. Exploratory Data Analysis (EDA) \\n5. Feature Engineering and Selection \\n6. Model Selection \\n7. Model Training \\n8. Model Evaluation and Tuning \\n9. Model Deployment \\n10. Model Monitoring and Maintenance \\n \\nMachine Learning Lifecycle'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 12}, page_content='13 \\nMachine Learning Operations \\nStep 1: Problem Definition \\nEmbarking on the machine learning journey involves a well-defined lifecycle, starting with the \\ncrucial step of problem definition. In this initial phase, stakeholders collaborate to identify the \\nbusiness problem at hand and frame it in a way that sets the stage for the entire process. \\nBy framing the problem in a comprehensive manner, the team establishes a foundation for the \\nentire machine learning lifecycle. Crucial elements, such as project objectives, desired \\noutcomes, and the scope of the task, are carefully delineated during this stage. \\nHere are the basic features of problem definition: \\n• \\nCollaboration: Work together with stakeholders to understand and define the business \\nproblem. \\n• \\nClarity: Clearly articulate the objectives, desired outcomes, and scope of the task. \\n• \\nFoundation: Establish a solid foundation for the machine learning process by framing \\nthe problem comprehensively. \\nStep 2: Data Collection \\nFollowing the precision of problem definition, the machine learning lifecycle progresses to the \\npivotal stage of data collection. This phase involves the systematic gathering of datasets that \\nwill serve as the raw material for model development. The quality and diversity of the data \\ncollected directly impact the robustness and generalizability of the machine learning model. \\nDuring data collection, practitioners must consider the relevance of the data to the defined \\nproblem, ensuring that the selected datasets encompass the necessary features and \\ncharacteristics. Additionally, factors such as data volume, quality, and ethical considerations \\nplay a crucial role in shaping the foundation for subsequent phases of the machine learning \\nlifecycle. A meticulous and well-organized approach to data collection lays the groundwork for \\neffective model training, evaluation, and deployment, ensuring that the resulting model is both \\naccurate and applicable to real-world scenarios. \\nHere are the basic features of Data Collection: \\n• \\nRelevance: Collect data that is relevant to the defined problem and includes necessary \\nfeatures. \\n• \\nQuality: Ensure data quality by considering factors like accuracy, completeness, and \\nethical considerations. \\n• \\nQuantity: Gather sufficient data volume to train a robust machine learning model. \\n• \\nDiversity: Include diverse datasets to capture a broad range of scenarios and patterns. \\nStep 3: Data Cleaning and Preprocessing \\nWith datasets in hand, the machine learning journey advances to the critical stages of data \\ncleaning and preprocessing. Raw data, is often messy and unstructured. Data cleaning involves \\naddressing issues such as missing values, outliers, and inconsistencies that could compromise \\nthe accuracy and reliability of the machine learning model.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 13}, page_content='14 \\nMachine Learning Operations \\nPreprocessing takes this a step further by standardizing formats, scaling values, and encoding \\ncategorical variables, creating a consistent and well-organized dataset. The objective is to refine \\nthe raw data into a format that facilitates meaningful analysis during subsequent phases of the \\nmachine learning lifecycle. By investing time and effort in data cleaning and preprocessing, \\npractitioners lay the foundation for robust model development, ensuring that the model is \\ntrained on high-quality, reliable data. \\nHere are the basic features of Data Cleaning and Preprocessing: \\n• \\nData Cleaning: Address issues such as missing values, outliers, and inconsistencies in \\nthe data. \\n• \\nData Preprocessing: Standardize formats, scale values, and encode categorical \\nvariables for consistency. \\n• \\nData Quality: Ensure that the data is well-organized and prepared for meaningful \\nanalysis. \\n• \\nData Integrity: Maintain the integrity of the dataset by cleaning and preprocessing it \\neffectively. \\nStep 4: Exploratory Data Analysis (EDA) \\nNow, focus turns to understanding the underlying patterns and characteristics of the collected \\ndata. Exploratory Data Analysis (EDA) emerges as a pivotal phase, where practitioners \\nleverage various statistical and visual tools to gain insights into the dataset’s structure. \\nDuring EDA, patterns, trends, and potential challenges are unearthed, providing valuable \\ncontext for subsequent decisions in the machine learning process. Visualizations, summary \\nstatistics, and correlation analyses offer a comprehensive view of the data, guiding practitioners \\ntoward informed choices in feature engineering, model selection, and other critical aspects. \\nEDA acts as a compass, directing the machine learning journey by revealing the intricacies of \\nthe data and informing the development of effective and accurate predictive models. \\nHere are the basic features of Exploratory Data Analysis: \\n• \\nExploration: Use statistical and visual tools to explore the structure and patterns in the \\ndata. \\n• \\nPatterns and Trends: Identify underlying patterns, trends, and potential challenges \\nwithin the dataset. \\n• \\nInsights: Gain valuable insights to inform decisions in later stages of the machine \\nlearning process. \\n• \\nDecision Making: Use exploratory data analysis to make informed decisions about \\nfeature engineering and model selection. \\nStep 5: Feature Engineering and Selection \\nFeature engineering takes center stage as a transformative process that elevates raw data into \\nmeaningful predictors. Simultaneously, feature selection refines this pool of variables, \\nidentifying the most relevant ones to enhance model efficiency and effectiveness.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 14}, page_content='15 \\nMachine Learning Operations \\nFeature engineering involves creating new features or transforming existing ones to better \\ncapture patterns and relationships within the data. This creative process requires domain \\nexpertise and a deep understanding of the problem at hand, ensuring that the engineered \\nfeatures contribute meaningfully to the predictive power of the model. On the other hand, \\nfeature selection focuses on identifying the subset of features that most significantly impact the \\nmodel’s performance. This dual approach seeks to strike a delicate balance, optimizing the \\nfeature set for predictive accuracy while minimizing computational complexity. \\nHere are the basic features of Feature Engineering and Selection: \\n• \\nFeature Engineering: Create new features or transform existing ones to better capture \\npatterns and relationships. \\n• \\nFeature Selection: Identify the subset of features that most significantly impact the \\nmodel’s performance. \\n• \\nDomain Expertise: Leverage domain knowledge to engineer features that contribute \\nmeaningfully to predictive power. \\n• \\nOptimization: Balance feature set for predictive accuracy while minimizing \\ncomputational complexity. \\nStep 6: Model Selection \\nNavigating the machine learning lifecycle requires the judicious selection of a model that aligns \\nwith the defined problem and the characteristics of the dataset. Model selection is a pivotal \\ndecision that determines the algorithmic framework guiding the predictive capabilities of the \\nmachine learning solution. The choice depends on the nature of the data, the complexity of the \\nproblem, and the desired outcomes. \\nHere are the basic features of Model Selection: \\n• \\nAlignment: Select a model that aligns with the defined problem and characteristics of \\nthe dataset. \\n• \\nComplexity: Consider the complexity of the problem and the nature of the data when \\nchoosing a model. \\n• \\nDecision Factors: Evaluate factors like performance, interpretability, and scalability \\nwhen selecting a model. \\n• \\nExperimentation: Experiment with different models to find the best fit for the problem \\nat hand. \\nStep 7: Model Training \\nWith the selected model in place, the machine learning lifecycle advances to the transformative \\nphase of model training. This process involves exposing the model to historical data, allowing \\nit to learn patterns, relationships, and dependencies within the dataset. \\nModel training is an iterative and dynamic journey, where the algorithm adjusts its parameters \\nto minimize errors and enhance predictive accuracy. During this phase, the model fine-tunes \\nits understanding of the data, optimizing its ability to make meaningful predictions. Rigorous'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 15}, page_content='16 \\nMachine Learning Operations \\nvalidation processes ensure that the trained model generalizes well to new, unseen data, \\nestablishing a foundation for reliable predictions in real-world scenarios. \\nHere are the basic features of Model Training: \\n• \\nTraining Data: Expose the model to historical data to learn patterns, relationships, and \\ndependencies. \\n• \\nIterative Process: Train the model iteratively, adjusting parameters to minimize errors \\nand enhance accuracy. \\n• \\nOptimization: Fine-tune the model’s understanding of the data to optimize predictive \\ncapabilities. \\n• \\nValidation: Rigorously validate the trained model to ensure generalization to new, \\nunseen data. \\nStep 8: Model Evaluation and Tuning \\nModel evaluation involves rigorous testing against validation datasets, employing metrics such \\nas accuracy, precision, recall, and F1 score to gauge its effectiveness. \\nEvaluation is a critical checkpoint, providing insights into the model’s strengths and \\nweaknesses. If the model falls short of desired performance levels, practitioners initiate model \\ntuning—a process that involves adjusting hyperparameters to enhance predictive accuracy. \\nThis iterative cycle of evaluation and tuning is crucial for achieving the desired level of model \\nrobustness and reliability. \\nHere are the basic features of Model Evaluation and Tuning: \\n• \\nEvaluation Metrics: Use metrics like accuracy, precision, recall, and F1 score to \\nevaluate model performance. \\n• \\nStrengths and Weaknesses: Identify the strengths and weaknesses of the model \\nthrough rigorous testing. \\n• \\nIterative Improvement: Initiate model tuning to adjust hyperparameters and enhance \\npredictive accuracy. \\n• \\nModel Robustness: Iterate through evaluation and tuning cycles to achieve desired \\nlevels of model robustness and reliability. \\nStep 9: Model Deployment \\nUpon successful evaluation, the machine learning model transitions from development to real-\\nworld application through the deployment phase. Model deployment involves integrating the \\npredictive solution into existing systems or processes, allowing stakeholders to leverage its \\ninsights for informed decision-making. \\nModel deployment marks the culmination of the machine learning lifecycle, transforming \\ntheoretical insights into practical solutions that drive tangible value for organizations. \\nHere are the basic features of Model Deployment:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 16}, page_content=\"17 \\nMachine Learning Operations \\n• \\nIntegration: Integrate the trained model into existing systems or processes for real-\\nworld application. \\n• \\nDecision Making: Use the model’s predictions to inform decision-making and drive \\ntangible value for organizations. \\n• \\nPractical Solutions: Deploy the model to transform theoretical insights into practical \\nsolutions that address business needs. \\n• \\nContinuous Improvement: Monitor model performance and make adjustments as \\nnecessary to maintain effectiveness over time. \\n \\nAI Platform notebooks (Tour) \\nAI Platform Notebooks on Google Cloud provide an easy and powerful environment for data \\nscientists to create and manage machine learning (ML) projects. Here's a simple explanation \\nwith examples: \\nManaged Jupyter Notebooks: \\n• \\nExplanation: These notebooks are enhanced versions of standard Jupyter notebooks. \\nGoogle Cloud manages the servers, so you don't have to worry about setting them up. \\n• \\nExample: You can run Python code to analyze data or train a machine learning model \\nusing TensorFlow, without having to install anything on your computer. Just open your \\nbrowser, and everything is ready for you. \\nCollaboration and Version Control: \\n• \\nExplanation: AI Platform Notebooks integrate with Git, allowing you to track changes \\nand collaborate with others easily. \\n• \\nExample: If you make a mistake in your code, you can use Git to revert to an earlier \\nversion. You can also work on the same project with your team, seeing each other's \\nchanges in real time. \\nCustomizable Hardware Profiles: \\n• \\nExplanation: You can choose the type of hardware you need for your project, whether \\nit's a powerful GPU for deep learning or just a CPU for data analysis. \\n• \\nExample: If you're training a complex neural network, you might select a GPU to speed \\nup the process. For simple tasks like data cleaning, you can stick with a basic CPU to \\nsave costs. \\nIntegrated with Google Cloud Services: \\n• \\nExplanation: The notebooks can connect to other Google Cloud services like \\nBigQuery and Cloud Storage, making it easy to access and analyze large datasets. \\n• \\nExample: You can query large datasets in BigQuery directly from your notebook and \\nvisualize the results with Matplotlib, all without leaving the notebook environment.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 17}, page_content=\"18 \\nMachine Learning Operations \\nHow to Get Started? \\n1. Create Your Notebook Instance: \\no Explanation: Use the Google Cloud Console to set up a new notebook \\nenvironment. \\no Example: Choose a notebook template with TensorFlow pre-installed if you're \\nplanning to build a neural network. \\n2. Write Some Code: \\no Explanation: Open your notebook and start coding. You can do everything \\nfrom data preprocessing to model training and visualization. \\no Example: Write Python code to load your dataset, train a machine learning \\nmodel, and plot the results using libraries like Pandas and Matplotlib. \\n3. Collaborate and Share: \\no Explanation: Share your notebook with colleagues to work together on the \\nproject. \\no Example: Invite your team to review your code, discuss the results, and make \\nimprovements collaboratively. \\n4. Debugging and Exploration: \\no Explanation: Use tools like the What-If Tool to understand how your model \\nworks and find any issues. \\no Example: Visualize how changes in input data affect your model's predictions, \\nhelping you improve its accuracy. \\nWhy Should You Care? \\n• \\nProductivity Boost: No need to worry about installing software or dealing with \\ndependencies. The environment is always ready for you. \\n• \\nScalability and Flexibility: Easily adjust the resources you need, scaling up or down \\nas required by your project. \\n• \\nData Science Nirvana: Focus on analyzing data and building models, while Google \\nCloud takes care of the infrastructure. You can even deploy your models directly from \\nthe notebook. \\n \\nDevelopment process – Computations and Storage \\nThe development process for AI Platform Notebooks involves several key stages, focusing on \\ncomputations and storage. Here's a simple breakdown: \\nDevelopment Process: Computations and Storage \\n1. Setting Up the Environment:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 18}, page_content='19 \\nMachine Learning Operations \\n• \\nCompute Resources: \\no Explanation: Choose the appropriate hardware for your project needs, such as \\nCPUs, GPUs, or TPUs. \\no Example: For training a large deep learning model, you might opt for a GPU to \\naccelerate computations. \\n• \\nStorage Options: \\no Explanation: Decide on the storage capacity required for your data and models. \\no Example: Use Google Cloud Storage for large datasets or to save model \\ncheckpoints during training. \\n2. Data Management: \\n• \\nData Ingestion: \\no Explanation: Import data from various sources into your notebook \\nenvironment. \\no Example: Load data from a CSV file stored in Google Cloud Storage or query \\na dataset from BigQuery. \\n• \\nData Preprocessing: \\no Explanation: Clean and prepare data for analysis and model training. \\no Example: Use Pandas to handle missing values and normalize data. \\n3. Model Development: \\n• \\nBuilding Models: \\no Explanation: Write and test code to create machine learning models using \\nlibraries like TensorFlow, PyTorch, or Scikit-learn. \\no Example: Develop a neural network for image classification using TensorFlow. \\n• \\nTraining Models: \\no Explanation: Use the chosen compute resources to train models on your \\ndataset. \\no Example: Train a model on a GPU to reduce training time for a complex neural \\nnetwork. \\n• \\nHyperparameter Tuning: \\no Explanation: Optimize model performance by adjusting hyperparameters. \\no Example: Use grid search or random search to find the best combination of \\nlearning rate and batch size. \\n4. Evaluation and Debugging: \\n• \\nModel Evaluation:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'file_path': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'format': 'PDF 1.7', 'title': '', 'author': 'Dr Selvam L', 'subject': '', 'keywords': '', 'moddate': '2025-08-18T07:12:05+05:30', 'trapped': '', 'modDate': \"D:20250818071205+05'30'\", 'creationDate': \"D:20240814234640+05'30'\", 'page': 19}, page_content='20 \\nMachine Learning Operations \\no Explanation: Assess model performance using appropriate metrics and \\nvalidation data. \\no Example: Calculate accuracy, precision, and recall for a classification model. \\n• \\nDebugging: \\no Explanation: Identify and fix issues in your code or model. \\no Example: Use the What-If Tool to analyze model predictions and understand \\nerrors. \\n5. Collaboration and Version Control: \\n• \\nCollaboration: \\no Explanation: Work with team members to improve and refine models. \\no Example: Share notebooks via Google Cloud and use comments to discuss \\ncode changes. \\n• \\nVersion Control: \\no Explanation: Use Git to track changes and maintain versions of your notebook. \\no Example: Revert to a previous version if a recent change caused an issue. \\n6. Deployment: \\n• \\nModel Deployment: \\no Explanation: \\nTransition \\nmodels \\nfrom \\ndevelopment \\nto \\nproduction \\nenvironments. \\no Example: Deploy a trained model using AI Platform Predictions to serve \\npredictions via an API. \\n• \\nMonitoring: \\no Explanation: Continuously monitor model performance in production. \\no Example: Set up alerts to track model accuracy and latency.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## load all the pdf files from the directory using PyMuPDFLoader\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/pdf\", #3parent\n",
    "    glob=\"**/*.pdf\", ## Pattern to match files  \n",
    "    loader_cls= PyMuPDFLoader, ##loader class to use\n",
    "    show_progress=True\n",
    "\n",
    ")\n",
    "\n",
    "pdf_documents=dir_loader.load()\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a923b4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}, page_content=\"1 \\nMachine Learning Operations \\nUNIT I \\nTwo Stages of ML \\nThe typical machine learning (ML) development process can be broken down into two \\nprimary stages: \\n1. Data Preparation and Model Training: \\no Data Collection and Preparation:  Gathering relevant data, cleaning it, and \\ntransforming it into a suitable format for model training. \\no Model Selection and Training:  Choosing an appropriate ML algorithm and \\ntraining it on the prepared data to learn patterns. \\n2. Model Evaluation and Deployment: \\no Model Evaluation: Assessing the model's performance on a separate dataset to \\nunderstand its accuracy and reliability. \\no Model Deployment:  Integrating the trained model into a production \\nenvironment to make predictions or decisions. \\nML in Google Products \\nGoogle is a pioneer in applying ML to its products. Some prominent examples include: \\n• Search Engine: Understanding search queries, ranking results, and providing relevant \\ninformation. \\n• Google Photos: Image recognition, object detection, and organization based on content. \\n• Google Translate: Real-time language translation using neural machine translation. \\n• Gmail: Spam filtering, smart reply, and priority inbox features. \\n• Google Assistant:  Natural language understanding, speech recognition, and task \\ncompletion. \\n \\nDialogflow \\nDialogflow (formerly known as Api.ai), is the platform owned by Google to build \\nconversational agents.  \\nInstead of building a chatbot from scratch, Dialogflow makes it easier to build it in considerably \\nless time and with bunch of Google features, including pre-build ML Models that can help you \\nget started right away. Dialogflow also allows you to integrate your conversational agent with \\npopular platforms like Google Assistant, Facebook Messenger, Twitter, Telegram and more. It \\nalso provides Web API to integrate the agent into Websites. \\nAccessing Dialogflow Console: \\n1) Visit https://dialogflow.com.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}, page_content='2 \\nMachine Learning Operations \\n \\n2) Sign-in using your Google Account and allow the access to Dialogflow.  \\n \\n3) Access the console by clicking Go to console button in the top-right corner.  \\n \\n \\nGetting familiar with Dialogflow Console:  \\n \\n \\nAgents \\nEvery Conversational Chatbot you make using Dialogflow are called  Agents. In the Console \\nyou can see all your agents in the top-left corner where you can configure the agent settings by \\nclicking Gear icon next to your agent name.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3'}, page_content='3 \\nMachine Learning Operations \\n \\nSections in Agent Settings: \\n• General: Here you can configure your Agent name, timezone and delete the agent. \\n• Export/Import: In this section you can backup and restore your Agents  (It is good \\npractice to Export your Agent periodically).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4'}, page_content='4 \\nMachine Learning Operations \\nIntents \\n \\nIntents comprises of what End-User’s intend to say. For every agent, there are intents defined \\nto fulfill End -User’s query. Each intent has a specific purpose. When User types a query, \\nDialogflow matches the particular intent and responds to the User. \\nYou can create an Intent using Create Intent button, or by using the  Plus icon next to Intent \\nin the Console Pane. \\nAfter opening an Intent, you enter the  Training Phrases. These are the example phrases that \\nUser will say. When User’s query resembles these phrases, Dialogflow will match the Intent. \\nYou need to define few phrases and the built-in Machine Learning will add more phrases over \\nthe time. \\n \\nIn the Responses section of Intent, you provide the statement which is used as the reply to the \\nUser’s Invocation Phrase. You can define multiple replies and Dialogflow will randomly \\nprovide a reply from the given responses.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5'}, page_content='5 \\nMachine Learning Operations \\n \\nOther than Training Phrases and Responses, another powerful feature of Dialogflow is Actions \\nand Parameters. In some intents you would like to obtain a particular data from User’s phrase. \\nYou can define parameters by right-clicking any phrase from the Invocation Phrases list, and \\nselect the Entity -type that suits your requirement. Dialogflow has built -in parame ters \\nlike sys.geo-location, sys.date and more. You can even define your own parameters (in the \\nEntities).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6'}, page_content='6 \\nMachine Learning Operations \\nEntities \\nEntities in context of Dialogflow are the set of Keywords that can be extracted as a parameter. \\nYou can define an Entity using  Create Entity or the Plus icon next to Entity in the Console \\nPane. \\nHere, each Entry in the Entity holds a specific keyword. These keywords can have several \\nsynonyms. Dialogflow allows you to define synonyms along with the keyword. \\n \\nFor example, if you define an entity “ GeographicalFeature” with entry “ Water Body” and \\ndefine synonyms as  lake, pond, ocean . When user says “I want to visit  ocean“. Dialogflow \\nunderstands the reference and extracts the parameter as “Water Body”. \\nEntities are really useful. These extracted parameters can be used to make conversations more \\nhuman-like (using Fulfillment). \\nFulfillment \\nUsing Fulfillment adds more functionality to your agent. You have to enable Fulfillment for \\neach Intent you require. There are two way to use the Fulfillment feature: \\n• Webhook'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7'}, page_content='7 \\nMachine Learning Operations \\nUsing Webhook, you can use externally deployed back-end to fulfill user query. The extracted \\nparameter are packed using JSON. In the Webhook section you just need to provide the URL \\nfor your back -end and during each invocation, Dialogflow will send the use r’s query and \\nParameters to the back-end. \\n• Inline Editor \\n \\nInline Editor allows you to manage fulfillment directly from the cloud functions. You need to \\nhave understanding of NodeJS to use Inline Editor. Here you can \\nmodify index.js and package.json according to the requirement of your agent. \\nIntegrations \\nAfter completing your agent, the last part is Integration. Here you can deploy your Agent to \\npopular services like Google Assistant, Facebook Messenger and more. Select the platform to \\ndeploy your agent.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8'}, page_content='8 \\nMachine Learning Operations'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9'}, page_content=\"9 \\nMachine Learning Operations \\n  \\nVision API \\nThe Vision API is a powerful tool that uses machine learning to understand the content \\nof images. It provides developers with a simple interface to access pre-trained models that can \\nextract information from images. \\nHow it works: \\n1. Image Upload: You send an image to the Vision API, either as an image file or an \\nimage URL. \\n2. Image Analysis:  The API processes the image using advanced machine learning \\nmodels. \\n3. Response: The API returns information about the image, such as labels, detected \\nobjects, or extracted text. \\nKey Features: \\n• Image Labeling: Identifies objects, places, and actions within an image. \\n• Face Detection:  Detects faces within an image and provides information about \\nattributes like emotions, landmarks, and poses. \\n• Optical Character Recognition (OCR):  Extracts printed and handwritten text from \\nimages. \\n• Landmark Detection: Identifies famous landmarks within an image. \\n• Logo Detection: Recognizes logos of popular brands. \\n• Image Properties: Provides information about image properties like dominant colors. \\n• Safe Search Detection: Identifies potentially sensitive content within images. \\n \\nGetting Started \\n1. Enable the Vision API: Visit the Google Cloud Platform console, navigate to the API & \\nServices section, and enable the Vision API for your project. \\n2. Set Up Authentication: Create a service account with appropriate permissions and \\ngenerate a key file. \\n3. Choose a Programming Language: The Vision API supports multiple languages, \\nincluding Python, Java, Node.js, and Go. \\n1. Enabling the Google Cloud Vision API \\nTo use the Google Cloud Vision API, you'll need to enable it for your Google Cloud project. \\nHere's a step-by-step guide:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10'}, page_content='10 \\nMachine Learning Operations \\nPrerequisites: \\n• A Google Cloud Platform (GCP) account. \\n• A Google Cloud project with billing enabled. \\nSteps: \\n1. Sign in to the Google Cloud Console: Visit https://console.cloud.google.com/ and sign \\nin with your Google account. \\n2. Select or Create a Project:  Choose an existing project or create a new one for your \\nVision API usage. \\n3. Enable the Vision API: \\no Navigate to the APIs & Services section in the console. \\no Search for \"Cloud Vision API\" and select it. \\no Click the Enable button. \\n2. Setting Up Authentication for the Google Cloud Vision API \\nTo use the Google Cloud Vision API, you\\'ll need to authenticate your requests. This ensures \\nthat Google can verify your identity and authorize access to the API. \\nUnderstanding Authentication Methods \\nThere are two primary methods for authenticating with the Google Cloud Vision API: \\n1. Application Default Credentials (ADC):  This method is suitable for local \\ndevelopment and testing. It automatically uses the credentials associated with your \\nGoogle account. \\n2. Service Accounts: For production environments and more granular control, service \\naccounts provide a robust authentication mechanism. \\nSetting Up Service Accounts \\n1. Create a Service Account: \\no Go to the Google Cloud Console and navigate to the IAM & Admin section. \\no Select \"Service accounts\" and click \"Create Service Account\". \\no Give your service account a name and description. \\no Grant the necessary roles to the service account. For Vision API, the \"Cloud \\nVision API User\" role is sufficient. \\n2. Create a Key: \\no Select the newly created service account and click the \"Keys\" tab. \\no Click \"Add Key\" and choose \"Create new key\". \\no Select the JSON key type and download the generated JSON file.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11'}, page_content=\"11 \\nMachine Learning Operations \\n3. Store the Key: \\no Securely store the JSON key file. You'll use this file to authenticate your API \\nrequests. \\n3. How to Choose a Programming Language \\nSelecting the right programming language for a project can be a daunting task. Here are some \\nkey factors to consider: \\nUnderstand Your Project Requirements \\n• Type of application:  Is it a web application, mobile app, desktop software, data \\nanalysis, or something else? \\n• Platform: Where will the application run (web, mobile, desktop, cloud)? \\n• Performance requirements: Are there specific speed or efficiency needs? \\n• Scalability: Will the application need to handle a large amount of data or users? \\n• Security needs: Are there sensitive data or security requirements? \\n• Team expertise: What languages are your team proficient in? \\nEvaluate Language Features \\n• Syntax and readability: How easy is the language to understand and maintain? \\n• Standard library: Does the language offer built-in functions for common tasks? \\n• Ecosystem: Is there a large and active community with libraries and frameworks? \\n• Performance: How fast is the language for different types of tasks? \\n• Cross-platform compatibility: Can the language be used for multiple platforms? \\n• Learning curve: How easy is it to learn the language? \\nPopular Languages and Their Use Cases \\n• Python: Versatile language for data science, machine learning, web development, and \\nscripting. \\n• JavaScript: Primarily used for web development, but also gaining popularity in other \\nareas. \\n• Java: Robust language for enterprise applications, Android app development, and big \\ndata processing. \\n• C++: High-performance language for system programming, game development, and \\nperformance-critical applications. \\n• C#: Used for Windows applications, game development, and web development with \\n.NET. \\n• Swift: Apple's language for iOS app development.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12'}, page_content='12 \\nMachine Learning Operations \\n• Kotlin: Modern language for Android app development and multiplatform \\ndevelopment. \\n \\n \\nML training phases \\nThe machine learning lifecycle is a process that guides the development and deployment of \\nmachine learning models in a structured way. It consists of various steps. \\nEach step plays a crucial role in ensuring the success and effectiveness of the machine learning \\nsolution. By following the machine learning lifecycle, organizations can solve complex \\nproblems systematically, leverage data -driven insights, and create scala ble and sustainable \\nmachine learning solutions that deliver tangible value. The steps to be followed in the machine \\nlearning lifecycle are: \\n1. Problem Definition \\n2. Data Collection \\n3. Data Cleaning and Preprocessing \\n4. Exploratory Data Analysis (EDA) \\n5. Feature Engineering and Selection \\n6. Model Selection \\n7. Model Training \\n8. Model Evaluation and Tuning \\n9. Model Deployment \\n10. Model Monitoring and Maintenance \\n \\nMachine Learning Lifecycle'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13'}, page_content='13 \\nMachine Learning Operations \\nStep 1: Problem Definition \\nEmbarking on the machine learning journey involves a well-defined lifecycle, starting with the \\ncrucial step of problem definition. In this initial phase, stakeholders collaborate to identify the \\nbusiness problem at hand and frame it in a way that sets the stage for the entire process. \\nBy framing the problem in a comprehensive manner, the team establishes a foundation for the \\nentire machine learning lifecycle. Crucial elements, such as  project objectives, desired \\noutcomes, and the scope of the task, are carefully delineated during this stage. \\nHere are the basic features of problem definition: \\n• Collaboration: Work together with stakeholders to understand and define the business \\nproblem. \\n• Clarity: Clearly articulate the objectives, desired outcomes, and scope of the task. \\n• Foundation: Establish a solid foundation for the machine learning process by framing \\nthe problem comprehensively. \\nStep 2: Data Collection \\nFollowing the precision of problem definition, the machine learning lifecycle progresses to the \\npivotal stage of data collection. This phase involves the systematic gathering of datasets that \\nwill serve as the raw material for model development. The qualit y and diversity of the data \\ncollected directly impact the robustness and generalizability of the machine learning model. \\nDuring data collection, practitioners must consider the relevance of the data to the defined \\nproblem, ensuring that the selected datasets encompass the necessary features and \\ncharacteristics. Additionally, factors such as data volume, quality, and ethical considerations \\nplay a crucial role in shaping the foundation for subsequent phases of the machine learning \\nlifecycle. A meticulous and well-organized approach to data collection lays the groundwork for \\neffective model training, evaluation, and deployment, ensuring that the resulting model is both \\naccurate and applicable to real-world scenarios. \\nHere are the basic features of Data Collection: \\n• Relevance: Collect data that is relevant to the defined problem and includes necessary \\nfeatures. \\n• Quality: Ensure data quality by considering factors like accuracy, completeness, and \\nethical considerations. \\n• Quantity: Gather sufficient data volume to train a robust machine learning model. \\n• Diversity: Include diverse datasets to capture a broad range of scenarios and patterns. \\nStep 3: Data Cleaning and Preprocessing \\nWith datasets in hand, the machine learning journey advances to the critical stages of  data \\ncleaning and preprocessing. Raw data, is often messy and unstructured. Data cleaning involves \\naddressing issues such as missing values, outliers, and inconsistencies that could compromise \\nthe accuracy and reliability of the machine learning model.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14'}, page_content='14 \\nMachine Learning Operations \\nPreprocessing takes this a step further by standardizing formats, scaling values, and encoding \\ncategorical variables, creating a consistent and well-organized dataset. The objective is to refine \\nthe raw data into a format that facilitates meaningful analysis during subsequent phases of the \\nmachine learning lifecycle. By investing time and effort in data cleaning and preprocessing, \\npractitioners lay the foundation for robust model development, ensuring that the model is \\ntrained on high-quality, reliable data. \\nHere are the basic features of Data Cleaning and Preprocessing: \\n• Data Cleaning: Address issues such as missing values, outliers, and inconsistencies in \\nthe data. \\n• Data Preprocessing:  Standardize formats, scale values, and encode categorical \\nvariables for consistency. \\n• Data Quality:  Ensure that the data is well -organized and prepared for meaningful \\nanalysis. \\n• Data Integrity: Maintain the integrity of the dataset by cleaning and preprocessing it \\neffectively. \\nStep 4: Exploratory Data Analysis (EDA) \\nNow, focus turns to understanding the underlying patterns and characteristics of the collected \\ndata. Exploratory Data Analysis (EDA) emerges as a pivotal phase, where practitioners \\nleverage various statistical and visual tools to gain insights into the dataset’s structure. \\nDuring EDA, patterns, trends, and potential challenges are unearthed, providing valuable \\ncontext for subsequent decisions in the machine learning process. Visualizations, summary \\nstatistics, and correlation analyses offer a comprehensive view of the data, guiding practitioners \\ntoward informed choices in  feature engineering, model selection, and other critical aspects. \\nEDA acts as a compass, directing the machine learning journey by revealing the intricacies of \\nthe data and informing the development of effective and accurate predictive models. \\nHere are the basic features of Exploratory Data Analysis: \\n• Exploration: Use statistical and visual tools to explore the structure and patterns in the \\ndata. \\n• Patterns and Trends:  Identify underlying patterns, trends, and potential challenges \\nwithin the dataset. \\n• Insights: Gain valuable insights to inform decisions in later stages of the machine \\nlearning process. \\n• Decision Making:  Use exploratory data analysis to make informed decisions about \\nfeature engineering and model selection. \\nStep 5: Feature Engineering and Selection \\nFeature engineering takes center stage as a transformative process that elevates raw data into \\nmeaningful predictors. Simultaneously,  feature selection  refines this pool of variables, \\nidentifying the most relevant ones to enhance model efficiency and effectiveness.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15'}, page_content='15 \\nMachine Learning Operations \\nFeature engineering involves creating new features or transforming existing ones to better \\ncapture patterns and relationships within the data. This creative process requires domain \\nexpertise and a deep understanding of the problem at hand, ensuring that th e engineered \\nfeatures contribute meaningfully to the predictive power of the model. On the other hand, \\nfeature selection focuses on identifying the subset of features that most significantly impact the \\nmodel’s performance. This dual approach seeks to strik e a delicate balance, optimizing the \\nfeature set for predictive accuracy while minimizing computational complexity. \\nHere are the basic features of Feature Engineering and Selection: \\n• Feature Engineering: Create new features or transform existing ones to better capture \\npatterns and relationships. \\n• Feature Selection: Identify the subset of features that most significantly impact the \\nmodel’s performance. \\n• Domain Expertise: Leverage domain knowledge to engineer features that contribute \\nmeaningfully to predictive power. \\n• Optimization: Balance feature set for predictive accuracy while minimizing \\ncomputational complexity. \\nStep 6: Model Selection \\nNavigating the machine learning lifecycle requires the judicious selection of a model that aligns \\nwith the defined problem and the characteristics of the dataset. Model selection is a pivotal \\ndecision that determines the algorithmic framework guiding the p redictive capabilities of the \\nmachine learning solution. The choice depends on the nature of the data, the complexity of the \\nproblem, and the desired outcomes. \\nHere are the basic features of Model Selection: \\n• Alignment: Select a model that aligns with the defined problem and characteristics of \\nthe dataset. \\n• Complexity: Consider the complexity of the problem and the nature of the data when \\nchoosing a model. \\n• Decision Factors: Evaluate factors like performance, interpretability, and scalability \\nwhen selecting a model. \\n• Experimentation: Experiment with different models to find the best fit for the problem \\nat hand. \\nStep 7: Model Training \\nWith the selected model in place, the machine learning lifecycle advances to the transformative \\nphase of model training. This process involves exposing the model to historical data, allowing \\nit to learn patterns, relationships, and dependencies within the dataset. \\nModel training is an iterative and dynamic journey, where the algorithm adjusts its parameters \\nto minimize errors and enhance predictive accuracy. During this phase, the model fine -tunes \\nits understanding of the data, optimizing its ability to make meaning ful predictions. Rigorous'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='16 \\nMachine Learning Operations \\nvalidation processes ensure that the trained model generalizes well to new, unseen data, \\nestablishing a foundation for reliable predictions in real-world scenarios. \\nHere are the basic features of Model Training: \\n• Training Data: Expose the model to historical data to learn patterns, relationships, and \\ndependencies. \\n• Iterative Process: Train the model iteratively, adjusting parameters to minimize errors \\nand enhance accuracy. \\n• Optimization: Fine-tune the model’s understanding of the data to optimize predictive \\ncapabilities. \\n• Validation: Rigorously validate the trained model to ensure generalization to new, \\nunseen data. \\nStep 8: Model Evaluation and Tuning \\nModel evaluation involves rigorous testing against validation datasets, employing metrics such \\nas accuracy, precision, recall, and F1 score to gauge its effectiveness. \\nEvaluation is a critical checkpoint, providing insights into the model’s strengths and \\nweaknesses. If the model falls short of desired performance levels, practitioners initiate model \\ntuning—a process that involves adjusting hyperparameters to enhance pred ictive accuracy. \\nThis iterative cycle of evaluation and tuning is crucial for achieving the desired level of model \\nrobustness and reliability. \\nHere are the basic features of Model Evaluation and Tuning: \\n• Evaluation Metrics:  Use metrics like accuracy, precision, recall, and F1 score to \\nevaluate model performance. \\n• Strengths and Weaknesses:  Identify the strengths and weaknesses of the model \\nthrough rigorous testing. \\n• Iterative Improvement: Initiate model tuning to adjust hyperparameters and enhance \\npredictive accuracy. \\n• Model Robustness:  Iterate through evaluation and tuning cycles to achieve desired \\nlevels of model robustness and reliability. \\nStep 9: Model Deployment \\nUpon successful evaluation, the machine learning model transitions from development to real-\\nworld application through the deployment phase. Model deployment involves integrating the \\npredictive solution into existing systems or processes, allowing stakehold ers to leverage its \\ninsights for informed decision-making. \\nModel deployment marks the culmination of the machine learning lifecycle, transforming \\ntheoretical insights into practical solutions that drive tangible value for organizations. \\nHere are the basic features of Model Deployment:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content=\"17 \\nMachine Learning Operations \\n• Integration: Integrate the trained model into existing systems or processes for real -\\nworld application. \\n• Decision Making: Use the model’s predictions to inform decision -making and drive \\ntangible value for organizations. \\n• Practical Solutions: Deploy the model to transform theoretical insights into practical \\nsolutions that address business needs. \\n• Continuous Improvement:  Monitor model performance and make adjustments as \\nnecessary to maintain effectiveness over time. \\n \\nAI Platform notebooks (Tour) \\nAI Platform Notebooks on Google Cloud provide an easy and powerful environment for data \\nscientists to create and manage machine learning (ML) projects. Here's a simple explanation \\nwith examples: \\nManaged Jupyter Notebooks: \\n• Explanation: These notebooks are enhanced versions of standard Jupyter notebooks. \\nGoogle Cloud manages the servers, so you don't have to worry about setting them up. \\n• Example: You can run Python code to analyze data or train a machine learning model \\nusing TensorFlow, without having to install anything on your computer. Just open your \\nbrowser, and everything is ready for you. \\nCollaboration and Version Control: \\n• Explanation: AI Platform Notebooks integrate with Git, allowing you to track changes \\nand collaborate with others easily. \\n• Example: If you make a mistake in your code, you can use Git to revert to an earlier \\nversion. You can also work on the same project with your team, seeing each other's \\nchanges in real time. \\nCustomizable Hardware Profiles: \\n• Explanation: You can choose the type of hardware you need for your project, whether \\nit's a powerful GPU for deep learning or just a CPU for data analysis. \\n• Example: If you're training a complex neural network, you might select a GPU to speed \\nup the process. For simple tasks like data cleaning, you can stick with a basic CPU to \\nsave costs. \\nIntegrated with Google Cloud Services: \\n• Explanation: The notebooks can connect to other Google Cloud services like \\nBigQuery and Cloud Storage, making it easy to access and analyze large datasets. \\n• Example: You can query large datasets in BigQuery directly from your notebook and \\nvisualize the results with Matplotlib, all without leaving the notebook environment.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content=\"18 \\nMachine Learning Operations \\nHow to Get Started? \\n1. Create Your Notebook Instance: \\no Explanation: Use the Google Cloud Console to set up a new notebook \\nenvironment. \\no Example: Choose a notebook template with TensorFlow pre-installed if you're \\nplanning to build a neural network. \\n2. Write Some Code: \\no Explanation: Open your notebook and start coding. You can do everything \\nfrom data preprocessing to model training and visualization. \\no Example: Write Python code to load your dataset, train a machine learning \\nmodel, and plot the results using libraries like Pandas and Matplotlib. \\n3. Collaborate and Share: \\no Explanation: Share your notebook with colleagues to work together on the \\nproject. \\no Example: Invite your team to review your code, discuss the results, and make \\nimprovements collaboratively. \\n4. Debugging and Exploration: \\no Explanation: Use tools like the What -If Tool to understand how your model \\nworks and find any issues. \\no Example: Visualize how changes in input data affect your model's predictions, \\nhelping you improve its accuracy. \\nWhy Should You Care? \\n• Productivity Boost:  No need to worry about installing software or dealing with \\ndependencies. The environment is always ready for you. \\n• Scalability and Flexibility: Easily adjust the resources you need, scaling up or down \\nas required by your project. \\n• Data Science Nirvana:  Focus on analyzing data and building models, while Google \\nCloud takes care of the infrastructure. You can even deploy your models directly from \\nthe notebook. \\n \\nDevelopment process – Computations and Storage \\nThe development process for AI Platform Notebooks involves several key stages, focusing on \\ncomputations and storage. Here's a simple breakdown: \\nDevelopment Process: Computations and Storage \\n1. Setting Up the Environment:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19'}, page_content='19 \\nMachine Learning Operations \\n• Compute Resources: \\no Explanation: Choose the appropriate hardware for your project needs, such as \\nCPUs, GPUs, or TPUs. \\no Example: For training a large deep learning model, you might opt for a GPU to \\naccelerate computations. \\n• Storage Options: \\no Explanation: Decide on the storage capacity required for your data and models. \\no Example: Use Google Cloud Storage for large datasets or to save model \\ncheckpoints during training. \\n2. Data Management: \\n• Data Ingestion: \\no Explanation: Import data from various sources into your notebook \\nenvironment. \\no Example: Load data from a CSV file stored in Google Cloud Storage or query \\na dataset from BigQuery. \\n• Data Preprocessing: \\no Explanation: Clean and prepare data for analysis and model training. \\no Example: Use Pandas to handle missing values and normalize data. \\n3. Model Development: \\n• Building Models: \\no Explanation: Write and test code to create machine learning models using \\nlibraries like TensorFlow, PyTorch, or Scikit-learn. \\no Example: Develop a neural network for image classification using TensorFlow. \\n• Training Models: \\no Explanation: Use the chosen compute resources to train models on your \\ndataset. \\no Example: Train a model on a GPU to reduce training time for a complex neural \\nnetwork. \\n• Hyperparameter Tuning: \\no Explanation: Optimize model performance by adjusting hyperparameters. \\no Example: Use grid search or random search to find the best combination of \\nlearning rate and batch size. \\n4. Evaluation and Debugging: \\n• Model Evaluation:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20'}, page_content='20 \\nMachine Learning Operations \\no Explanation: Assess model performance using appropriate metrics and \\nvalidation data. \\no Example: Calculate accuracy, precision, and recall for a classification model. \\n• Debugging: \\no Explanation: Identify and fix issues in your code or model. \\no Example: Use the What-If Tool to analyze model predictions and understand \\nerrors. \\n5. Collaboration and Version Control: \\n• Collaboration: \\no Explanation: Work with team members to improve and refine models. \\no Example: Share notebooks via Google Cloud and use comments to discuss \\ncode changes. \\n• Version Control: \\no Explanation: Use Git to track changes and maintain versions of your notebook. \\no Example: Revert to a previous version if a recent change caused an issue. \\n6. Deployment: \\n• Model Deployment: \\no Explanation: Transition models from development to production \\nenvironments. \\no Example: Deploy a trained model using AI Platform Predictions to serve \\npredictions via an API. \\n• Monitoring: \\no Explanation: Continuously monitor model performance in production. \\no Example: Set up alerts to track model accuracy and latency.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## load all the pdf files from the directory using PyMuPDFLoader\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/pdf\", #3parent\n",
    "    glob=\"**/*.pdf\", ## Pattern to match files  \n",
    "    loader_cls= PyPDFLoader, ##loader class to use\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "pdf_documents1=dir_loader.load()\n",
    "pdf_documents1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdd1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_documents[0])\n",
    "#use langchain document loader wesite https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbc3b9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}, page_content=\"1 \\nMachine Learning Operations \\nUNIT I \\nTwo Stages of ML \\nThe typical machine learning (ML) development process can be broken down into two \\nprimary stages: \\n1. Data Preparation and Model Training: \\no Data Collection and Preparation:  Gathering relevant data, cleaning it, and \\ntransforming it into a suitable format for model training. \\no Model Selection and Training:  Choosing an appropriate ML algorithm and \\ntraining it on the prepared data to learn patterns. \\n2. Model Evaluation and Deployment: \\no Model Evaluation: Assessing the model's performance on a separate dataset to \\nunderstand its accuracy and reliability. \\no Model Deployment:  Integrating the trained model into a production \\nenvironment to make predictions or decisions. \\nML in Google Products \\nGoogle is a pioneer in applying ML to its products. Some prominent examples include: \\n• Search Engine: Understanding search queries, ranking results, and providing relevant \\ninformation. \\n• Google Photos: Image recognition, object detection, and organization based on content. \\n• Google Translate: Real-time language translation using neural machine translation. \\n• Gmail: Spam filtering, smart reply, and priority inbox features. \\n• Google Assistant:  Natural language understanding, speech recognition, and task \\ncompletion. \\n \\nDialogflow \\nDialogflow (formerly known as Api.ai), is the platform owned by Google to build \\nconversational agents.  \\nInstead of building a chatbot from scratch, Dialogflow makes it easier to build it in considerably \\nless time and with bunch of Google features, including pre-build ML Models that can help you \\nget started right away. Dialogflow also allows you to integrate your conversational agent with \\npopular platforms like Google Assistant, Facebook Messenger, Twitter, Telegram and more. It \\nalso provides Web API to integrate the agent into Websites. \\nAccessing Dialogflow Console: \\n1) Visit https://dialogflow.com.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}, page_content='2 \\nMachine Learning Operations \\n \\n2) Sign-in using your Google Account and allow the access to Dialogflow.  \\n \\n3) Access the console by clicking Go to console button in the top-right corner.  \\n \\n \\nGetting familiar with Dialogflow Console:  \\n \\n \\nAgents \\nEvery Conversational Chatbot you make using Dialogflow are called  Agents. In the Console \\nyou can see all your agents in the top-left corner where you can configure the agent settings by \\nclicking Gear icon next to your agent name.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3'}, page_content='3 \\nMachine Learning Operations \\n \\nSections in Agent Settings: \\n• General: Here you can configure your Agent name, timezone and delete the agent. \\n• Export/Import: In this section you can backup and restore your Agents  (It is good \\npractice to Export your Agent periodically).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4'}, page_content='4 \\nMachine Learning Operations \\nIntents \\n \\nIntents comprises of what End-User’s intend to say. For every agent, there are intents defined \\nto fulfill End -User’s query. Each intent has a specific purpose. When User types a query, \\nDialogflow matches the particular intent and responds to the User. \\nYou can create an Intent using Create Intent button, or by using the  Plus icon next to Intent \\nin the Console Pane. \\nAfter opening an Intent, you enter the  Training Phrases. These are the example phrases that \\nUser will say. When User’s query resembles these phrases, Dialogflow will match the Intent. \\nYou need to define few phrases and the built-in Machine Learning will add more phrases over \\nthe time. \\n \\nIn the Responses section of Intent, you provide the statement which is used as the reply to the \\nUser’s Invocation Phrase. You can define multiple replies and Dialogflow will randomly \\nprovide a reply from the given responses.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5'}, page_content='5 \\nMachine Learning Operations \\n \\nOther than Training Phrases and Responses, another powerful feature of Dialogflow is Actions \\nand Parameters. In some intents you would like to obtain a particular data from User’s phrase. \\nYou can define parameters by right-clicking any phrase from the Invocation Phrases list, and \\nselect the Entity -type that suits your requirement. Dialogflow has built -in parame ters \\nlike sys.geo-location, sys.date and more. You can even define your own parameters (in the \\nEntities).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6'}, page_content='6 \\nMachine Learning Operations \\nEntities \\nEntities in context of Dialogflow are the set of Keywords that can be extracted as a parameter. \\nYou can define an Entity using  Create Entity or the Plus icon next to Entity in the Console \\nPane. \\nHere, each Entry in the Entity holds a specific keyword. These keywords can have several \\nsynonyms. Dialogflow allows you to define synonyms along with the keyword. \\n \\nFor example, if you define an entity “ GeographicalFeature” with entry “ Water Body” and \\ndefine synonyms as  lake, pond, ocean . When user says “I want to visit  ocean“. Dialogflow \\nunderstands the reference and extracts the parameter as “Water Body”. \\nEntities are really useful. These extracted parameters can be used to make conversations more \\nhuman-like (using Fulfillment). \\nFulfillment \\nUsing Fulfillment adds more functionality to your agent. You have to enable Fulfillment for \\neach Intent you require. There are two way to use the Fulfillment feature: \\n• Webhook'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7'}, page_content='7 \\nMachine Learning Operations \\nUsing Webhook, you can use externally deployed back-end to fulfill user query. The extracted \\nparameter are packed using JSON. In the Webhook section you just need to provide the URL \\nfor your back -end and during each invocation, Dialogflow will send the use r’s query and \\nParameters to the back-end. \\n• Inline Editor \\n \\nInline Editor allows you to manage fulfillment directly from the cloud functions. You need to \\nhave understanding of NodeJS to use Inline Editor. Here you can \\nmodify index.js and package.json according to the requirement of your agent. \\nIntegrations \\nAfter completing your agent, the last part is Integration. Here you can deploy your Agent to \\npopular services like Google Assistant, Facebook Messenger and more. Select the platform to \\ndeploy your agent.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8'}, page_content='8 \\nMachine Learning Operations'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9'}, page_content=\"9 \\nMachine Learning Operations \\n  \\nVision API \\nThe Vision API is a powerful tool that uses machine learning to understand the content \\nof images. It provides developers with a simple interface to access pre-trained models that can \\nextract information from images. \\nHow it works: \\n1. Image Upload: You send an image to the Vision API, either as an image file or an \\nimage URL. \\n2. Image Analysis:  The API processes the image using advanced machine learning \\nmodels. \\n3. Response: The API returns information about the image, such as labels, detected \\nobjects, or extracted text. \\nKey Features: \\n• Image Labeling: Identifies objects, places, and actions within an image. \\n• Face Detection:  Detects faces within an image and provides information about \\nattributes like emotions, landmarks, and poses. \\n• Optical Character Recognition (OCR):  Extracts printed and handwritten text from \\nimages. \\n• Landmark Detection: Identifies famous landmarks within an image. \\n• Logo Detection: Recognizes logos of popular brands. \\n• Image Properties: Provides information about image properties like dominant colors. \\n• Safe Search Detection: Identifies potentially sensitive content within images. \\n \\nGetting Started \\n1. Enable the Vision API: Visit the Google Cloud Platform console, navigate to the API & \\nServices section, and enable the Vision API for your project. \\n2. Set Up Authentication: Create a service account with appropriate permissions and \\ngenerate a key file. \\n3. Choose a Programming Language: The Vision API supports multiple languages, \\nincluding Python, Java, Node.js, and Go. \\n1. Enabling the Google Cloud Vision API \\nTo use the Google Cloud Vision API, you'll need to enable it for your Google Cloud project. \\nHere's a step-by-step guide:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10'}, page_content='10 \\nMachine Learning Operations \\nPrerequisites: \\n• A Google Cloud Platform (GCP) account. \\n• A Google Cloud project with billing enabled. \\nSteps: \\n1. Sign in to the Google Cloud Console: Visit https://console.cloud.google.com/ and sign \\nin with your Google account. \\n2. Select or Create a Project:  Choose an existing project or create a new one for your \\nVision API usage. \\n3. Enable the Vision API: \\no Navigate to the APIs & Services section in the console. \\no Search for \"Cloud Vision API\" and select it. \\no Click the Enable button. \\n2. Setting Up Authentication for the Google Cloud Vision API \\nTo use the Google Cloud Vision API, you\\'ll need to authenticate your requests. This ensures \\nthat Google can verify your identity and authorize access to the API. \\nUnderstanding Authentication Methods \\nThere are two primary methods for authenticating with the Google Cloud Vision API: \\n1. Application Default Credentials (ADC):  This method is suitable for local \\ndevelopment and testing. It automatically uses the credentials associated with your \\nGoogle account. \\n2. Service Accounts: For production environments and more granular control, service \\naccounts provide a robust authentication mechanism. \\nSetting Up Service Accounts \\n1. Create a Service Account: \\no Go to the Google Cloud Console and navigate to the IAM & Admin section. \\no Select \"Service accounts\" and click \"Create Service Account\". \\no Give your service account a name and description. \\no Grant the necessary roles to the service account. For Vision API, the \"Cloud \\nVision API User\" role is sufficient. \\n2. Create a Key: \\no Select the newly created service account and click the \"Keys\" tab. \\no Click \"Add Key\" and choose \"Create new key\". \\no Select the JSON key type and download the generated JSON file.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11'}, page_content=\"11 \\nMachine Learning Operations \\n3. Store the Key: \\no Securely store the JSON key file. You'll use this file to authenticate your API \\nrequests. \\n3. How to Choose a Programming Language \\nSelecting the right programming language for a project can be a daunting task. Here are some \\nkey factors to consider: \\nUnderstand Your Project Requirements \\n• Type of application:  Is it a web application, mobile app, desktop software, data \\nanalysis, or something else? \\n• Platform: Where will the application run (web, mobile, desktop, cloud)? \\n• Performance requirements: Are there specific speed or efficiency needs? \\n• Scalability: Will the application need to handle a large amount of data or users? \\n• Security needs: Are there sensitive data or security requirements? \\n• Team expertise: What languages are your team proficient in? \\nEvaluate Language Features \\n• Syntax and readability: How easy is the language to understand and maintain? \\n• Standard library: Does the language offer built-in functions for common tasks? \\n• Ecosystem: Is there a large and active community with libraries and frameworks? \\n• Performance: How fast is the language for different types of tasks? \\n• Cross-platform compatibility: Can the language be used for multiple platforms? \\n• Learning curve: How easy is it to learn the language? \\nPopular Languages and Their Use Cases \\n• Python: Versatile language for data science, machine learning, web development, and \\nscripting. \\n• JavaScript: Primarily used for web development, but also gaining popularity in other \\nareas. \\n• Java: Robust language for enterprise applications, Android app development, and big \\ndata processing. \\n• C++: High-performance language for system programming, game development, and \\nperformance-critical applications. \\n• C#: Used for Windows applications, game development, and web development with \\n.NET. \\n• Swift: Apple's language for iOS app development.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12'}, page_content='12 \\nMachine Learning Operations \\n• Kotlin: Modern language for Android app development and multiplatform \\ndevelopment. \\n \\n \\nML training phases \\nThe machine learning lifecycle is a process that guides the development and deployment of \\nmachine learning models in a structured way. It consists of various steps. \\nEach step plays a crucial role in ensuring the success and effectiveness of the machine learning \\nsolution. By following the machine learning lifecycle, organizations can solve complex \\nproblems systematically, leverage data -driven insights, and create scala ble and sustainable \\nmachine learning solutions that deliver tangible value. The steps to be followed in the machine \\nlearning lifecycle are: \\n1. Problem Definition \\n2. Data Collection \\n3. Data Cleaning and Preprocessing \\n4. Exploratory Data Analysis (EDA) \\n5. Feature Engineering and Selection \\n6. Model Selection \\n7. Model Training \\n8. Model Evaluation and Tuning \\n9. Model Deployment \\n10. Model Monitoring and Maintenance \\n \\nMachine Learning Lifecycle'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13'}, page_content='13 \\nMachine Learning Operations \\nStep 1: Problem Definition \\nEmbarking on the machine learning journey involves a well-defined lifecycle, starting with the \\ncrucial step of problem definition. In this initial phase, stakeholders collaborate to identify the \\nbusiness problem at hand and frame it in a way that sets the stage for the entire process. \\nBy framing the problem in a comprehensive manner, the team establishes a foundation for the \\nentire machine learning lifecycle. Crucial elements, such as  project objectives, desired \\noutcomes, and the scope of the task, are carefully delineated during this stage. \\nHere are the basic features of problem definition: \\n• Collaboration: Work together with stakeholders to understand and define the business \\nproblem. \\n• Clarity: Clearly articulate the objectives, desired outcomes, and scope of the task. \\n• Foundation: Establish a solid foundation for the machine learning process by framing \\nthe problem comprehensively. \\nStep 2: Data Collection \\nFollowing the precision of problem definition, the machine learning lifecycle progresses to the \\npivotal stage of data collection. This phase involves the systematic gathering of datasets that \\nwill serve as the raw material for model development. The qualit y and diversity of the data \\ncollected directly impact the robustness and generalizability of the machine learning model. \\nDuring data collection, practitioners must consider the relevance of the data to the defined \\nproblem, ensuring that the selected datasets encompass the necessary features and \\ncharacteristics. Additionally, factors such as data volume, quality, and ethical considerations \\nplay a crucial role in shaping the foundation for subsequent phases of the machine learning \\nlifecycle. A meticulous and well-organized approach to data collection lays the groundwork for \\neffective model training, evaluation, and deployment, ensuring that the resulting model is both \\naccurate and applicable to real-world scenarios. \\nHere are the basic features of Data Collection: \\n• Relevance: Collect data that is relevant to the defined problem and includes necessary \\nfeatures. \\n• Quality: Ensure data quality by considering factors like accuracy, completeness, and \\nethical considerations. \\n• Quantity: Gather sufficient data volume to train a robust machine learning model. \\n• Diversity: Include diverse datasets to capture a broad range of scenarios and patterns. \\nStep 3: Data Cleaning and Preprocessing \\nWith datasets in hand, the machine learning journey advances to the critical stages of  data \\ncleaning and preprocessing. Raw data, is often messy and unstructured. Data cleaning involves \\naddressing issues such as missing values, outliers, and inconsistencies that could compromise \\nthe accuracy and reliability of the machine learning model.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14'}, page_content='14 \\nMachine Learning Operations \\nPreprocessing takes this a step further by standardizing formats, scaling values, and encoding \\ncategorical variables, creating a consistent and well-organized dataset. The objective is to refine \\nthe raw data into a format that facilitates meaningful analysis during subsequent phases of the \\nmachine learning lifecycle. By investing time and effort in data cleaning and preprocessing, \\npractitioners lay the foundation for robust model development, ensuring that the model is \\ntrained on high-quality, reliable data. \\nHere are the basic features of Data Cleaning and Preprocessing: \\n• Data Cleaning: Address issues such as missing values, outliers, and inconsistencies in \\nthe data. \\n• Data Preprocessing:  Standardize formats, scale values, and encode categorical \\nvariables for consistency. \\n• Data Quality:  Ensure that the data is well -organized and prepared for meaningful \\nanalysis. \\n• Data Integrity: Maintain the integrity of the dataset by cleaning and preprocessing it \\neffectively. \\nStep 4: Exploratory Data Analysis (EDA) \\nNow, focus turns to understanding the underlying patterns and characteristics of the collected \\ndata. Exploratory Data Analysis (EDA) emerges as a pivotal phase, where practitioners \\nleverage various statistical and visual tools to gain insights into the dataset’s structure. \\nDuring EDA, patterns, trends, and potential challenges are unearthed, providing valuable \\ncontext for subsequent decisions in the machine learning process. Visualizations, summary \\nstatistics, and correlation analyses offer a comprehensive view of the data, guiding practitioners \\ntoward informed choices in  feature engineering, model selection, and other critical aspects. \\nEDA acts as a compass, directing the machine learning journey by revealing the intricacies of \\nthe data and informing the development of effective and accurate predictive models. \\nHere are the basic features of Exploratory Data Analysis: \\n• Exploration: Use statistical and visual tools to explore the structure and patterns in the \\ndata. \\n• Patterns and Trends:  Identify underlying patterns, trends, and potential challenges \\nwithin the dataset. \\n• Insights: Gain valuable insights to inform decisions in later stages of the machine \\nlearning process. \\n• Decision Making:  Use exploratory data analysis to make informed decisions about \\nfeature engineering and model selection. \\nStep 5: Feature Engineering and Selection \\nFeature engineering takes center stage as a transformative process that elevates raw data into \\nmeaningful predictors. Simultaneously,  feature selection  refines this pool of variables, \\nidentifying the most relevant ones to enhance model efficiency and effectiveness.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15'}, page_content='15 \\nMachine Learning Operations \\nFeature engineering involves creating new features or transforming existing ones to better \\ncapture patterns and relationships within the data. This creative process requires domain \\nexpertise and a deep understanding of the problem at hand, ensuring that th e engineered \\nfeatures contribute meaningfully to the predictive power of the model. On the other hand, \\nfeature selection focuses on identifying the subset of features that most significantly impact the \\nmodel’s performance. This dual approach seeks to strik e a delicate balance, optimizing the \\nfeature set for predictive accuracy while minimizing computational complexity. \\nHere are the basic features of Feature Engineering and Selection: \\n• Feature Engineering: Create new features or transform existing ones to better capture \\npatterns and relationships. \\n• Feature Selection: Identify the subset of features that most significantly impact the \\nmodel’s performance. \\n• Domain Expertise: Leverage domain knowledge to engineer features that contribute \\nmeaningfully to predictive power. \\n• Optimization: Balance feature set for predictive accuracy while minimizing \\ncomputational complexity. \\nStep 6: Model Selection \\nNavigating the machine learning lifecycle requires the judicious selection of a model that aligns \\nwith the defined problem and the characteristics of the dataset. Model selection is a pivotal \\ndecision that determines the algorithmic framework guiding the p redictive capabilities of the \\nmachine learning solution. The choice depends on the nature of the data, the complexity of the \\nproblem, and the desired outcomes. \\nHere are the basic features of Model Selection: \\n• Alignment: Select a model that aligns with the defined problem and characteristics of \\nthe dataset. \\n• Complexity: Consider the complexity of the problem and the nature of the data when \\nchoosing a model. \\n• Decision Factors: Evaluate factors like performance, interpretability, and scalability \\nwhen selecting a model. \\n• Experimentation: Experiment with different models to find the best fit for the problem \\nat hand. \\nStep 7: Model Training \\nWith the selected model in place, the machine learning lifecycle advances to the transformative \\nphase of model training. This process involves exposing the model to historical data, allowing \\nit to learn patterns, relationships, and dependencies within the dataset. \\nModel training is an iterative and dynamic journey, where the algorithm adjusts its parameters \\nto minimize errors and enhance predictive accuracy. During this phase, the model fine -tunes \\nits understanding of the data, optimizing its ability to make meaning ful predictions. Rigorous'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='16 \\nMachine Learning Operations \\nvalidation processes ensure that the trained model generalizes well to new, unseen data, \\nestablishing a foundation for reliable predictions in real-world scenarios. \\nHere are the basic features of Model Training: \\n• Training Data: Expose the model to historical data to learn patterns, relationships, and \\ndependencies. \\n• Iterative Process: Train the model iteratively, adjusting parameters to minimize errors \\nand enhance accuracy. \\n• Optimization: Fine-tune the model’s understanding of the data to optimize predictive \\ncapabilities. \\n• Validation: Rigorously validate the trained model to ensure generalization to new, \\nunseen data. \\nStep 8: Model Evaluation and Tuning \\nModel evaluation involves rigorous testing against validation datasets, employing metrics such \\nas accuracy, precision, recall, and F1 score to gauge its effectiveness. \\nEvaluation is a critical checkpoint, providing insights into the model’s strengths and \\nweaknesses. If the model falls short of desired performance levels, practitioners initiate model \\ntuning—a process that involves adjusting hyperparameters to enhance pred ictive accuracy. \\nThis iterative cycle of evaluation and tuning is crucial for achieving the desired level of model \\nrobustness and reliability. \\nHere are the basic features of Model Evaluation and Tuning: \\n• Evaluation Metrics:  Use metrics like accuracy, precision, recall, and F1 score to \\nevaluate model performance. \\n• Strengths and Weaknesses:  Identify the strengths and weaknesses of the model \\nthrough rigorous testing. \\n• Iterative Improvement: Initiate model tuning to adjust hyperparameters and enhance \\npredictive accuracy. \\n• Model Robustness:  Iterate through evaluation and tuning cycles to achieve desired \\nlevels of model robustness and reliability. \\nStep 9: Model Deployment \\nUpon successful evaluation, the machine learning model transitions from development to real-\\nworld application through the deployment phase. Model deployment involves integrating the \\npredictive solution into existing systems or processes, allowing stakehold ers to leverage its \\ninsights for informed decision-making. \\nModel deployment marks the culmination of the machine learning lifecycle, transforming \\ntheoretical insights into practical solutions that drive tangible value for organizations. \\nHere are the basic features of Model Deployment:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content=\"17 \\nMachine Learning Operations \\n• Integration: Integrate the trained model into existing systems or processes for real -\\nworld application. \\n• Decision Making: Use the model’s predictions to inform decision -making and drive \\ntangible value for organizations. \\n• Practical Solutions: Deploy the model to transform theoretical insights into practical \\nsolutions that address business needs. \\n• Continuous Improvement:  Monitor model performance and make adjustments as \\nnecessary to maintain effectiveness over time. \\n \\nAI Platform notebooks (Tour) \\nAI Platform Notebooks on Google Cloud provide an easy and powerful environment for data \\nscientists to create and manage machine learning (ML) projects. Here's a simple explanation \\nwith examples: \\nManaged Jupyter Notebooks: \\n• Explanation: These notebooks are enhanced versions of standard Jupyter notebooks. \\nGoogle Cloud manages the servers, so you don't have to worry about setting them up. \\n• Example: You can run Python code to analyze data or train a machine learning model \\nusing TensorFlow, without having to install anything on your computer. Just open your \\nbrowser, and everything is ready for you. \\nCollaboration and Version Control: \\n• Explanation: AI Platform Notebooks integrate with Git, allowing you to track changes \\nand collaborate with others easily. \\n• Example: If you make a mistake in your code, you can use Git to revert to an earlier \\nversion. You can also work on the same project with your team, seeing each other's \\nchanges in real time. \\nCustomizable Hardware Profiles: \\n• Explanation: You can choose the type of hardware you need for your project, whether \\nit's a powerful GPU for deep learning or just a CPU for data analysis. \\n• Example: If you're training a complex neural network, you might select a GPU to speed \\nup the process. For simple tasks like data cleaning, you can stick with a basic CPU to \\nsave costs. \\nIntegrated with Google Cloud Services: \\n• Explanation: The notebooks can connect to other Google Cloud services like \\nBigQuery and Cloud Storage, making it easy to access and analyze large datasets. \\n• Example: You can query large datasets in BigQuery directly from your notebook and \\nvisualize the results with Matplotlib, all without leaving the notebook environment.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content=\"18 \\nMachine Learning Operations \\nHow to Get Started? \\n1. Create Your Notebook Instance: \\no Explanation: Use the Google Cloud Console to set up a new notebook \\nenvironment. \\no Example: Choose a notebook template with TensorFlow pre-installed if you're \\nplanning to build a neural network. \\n2. Write Some Code: \\no Explanation: Open your notebook and start coding. You can do everything \\nfrom data preprocessing to model training and visualization. \\no Example: Write Python code to load your dataset, train a machine learning \\nmodel, and plot the results using libraries like Pandas and Matplotlib. \\n3. Collaborate and Share: \\no Explanation: Share your notebook with colleagues to work together on the \\nproject. \\no Example: Invite your team to review your code, discuss the results, and make \\nimprovements collaboratively. \\n4. Debugging and Exploration: \\no Explanation: Use tools like the What -If Tool to understand how your model \\nworks and find any issues. \\no Example: Visualize how changes in input data affect your model's predictions, \\nhelping you improve its accuracy. \\nWhy Should You Care? \\n• Productivity Boost:  No need to worry about installing software or dealing with \\ndependencies. The environment is always ready for you. \\n• Scalability and Flexibility: Easily adjust the resources you need, scaling up or down \\nas required by your project. \\n• Data Science Nirvana:  Focus on analyzing data and building models, while Google \\nCloud takes care of the infrastructure. You can even deploy your models directly from \\nthe notebook. \\n \\nDevelopment process – Computations and Storage \\nThe development process for AI Platform Notebooks involves several key stages, focusing on \\ncomputations and storage. Here's a simple breakdown: \\nDevelopment Process: Computations and Storage \\n1. Setting Up the Environment:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19'}, page_content='19 \\nMachine Learning Operations \\n• Compute Resources: \\no Explanation: Choose the appropriate hardware for your project needs, such as \\nCPUs, GPUs, or TPUs. \\no Example: For training a large deep learning model, you might opt for a GPU to \\naccelerate computations. \\n• Storage Options: \\no Explanation: Decide on the storage capacity required for your data and models. \\no Example: Use Google Cloud Storage for large datasets or to save model \\ncheckpoints during training. \\n2. Data Management: \\n• Data Ingestion: \\no Explanation: Import data from various sources into your notebook \\nenvironment. \\no Example: Load data from a CSV file stored in Google Cloud Storage or query \\na dataset from BigQuery. \\n• Data Preprocessing: \\no Explanation: Clean and prepare data for analysis and model training. \\no Example: Use Pandas to handle missing values and normalize data. \\n3. Model Development: \\n• Building Models: \\no Explanation: Write and test code to create machine learning models using \\nlibraries like TensorFlow, PyTorch, or Scikit-learn. \\no Example: Develop a neural network for image classification using TensorFlow. \\n• Training Models: \\no Explanation: Use the chosen compute resources to train models on your \\ndataset. \\no Example: Train a model on a GPU to reduce training time for a complex neural \\nnetwork. \\n• Hyperparameter Tuning: \\no Explanation: Optimize model performance by adjusting hyperparameters. \\no Example: Use grid search or random search to find the best combination of \\nlearning rate and batch size. \\n4. Evaluation and Debugging: \\n• Model Evaluation:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20'}, page_content='20 \\nMachine Learning Operations \\no Explanation: Assess model performance using appropriate metrics and \\nvalidation data. \\no Example: Calculate accuracy, precision, and recall for a classification model. \\n• Debugging: \\no Explanation: Identify and fix issues in your code or model. \\no Example: Use the What-If Tool to analyze model predictions and understand \\nerrors. \\n5. Collaboration and Version Control: \\n• Collaboration: \\no Explanation: Work with team members to improve and refine models. \\no Example: Share notebooks via Google Cloud and use comments to discuss \\ncode changes. \\n• Version Control: \\no Explanation: Use Git to track changes and maintain versions of your notebook. \\no Example: Revert to a previous version if a recent change caused an issue. \\n6. Deployment: \\n• Model Deployment: \\no Explanation: Transition models from development to production \\nenvironments. \\no Example: Deploy a trained model using AI Platform Predictions to serve \\npredictions via an API. \\n• Monitoring: \\no Explanation: Continuously monitor model performance in production. \\no Example: Set up alerts to track model accuracy and latency.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e207cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72ab0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "452c67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Dict, Any,Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1a235ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: all-MiniLM-L6-v2\n",
      "Model loaded successfully: 384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            print(f\"Loading model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embedding(self, texts: List[str]) -> np.ndarray:\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        print(f\"Generating embeddings for {len(texts)} texts\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "# initialize embedding manager\n",
    "embedding_manager = EmbeddingManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c340266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x179d3ffdd30>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID for a spefic document\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3838dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 20 documents into 45 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: 1 \n",
      "Machine Learning Operations \n",
      "UNIT I \n",
      "Two Stages of ML \n",
      "The typical machine learning (ML) development process can be broken down into two \n",
      "primary stages: \n",
      "1. Data Preparation and Model Training: \n",
      "o...\n",
      "Metadata: {'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}, page_content=\"1 \\nMachine Learning Operations \\nUNIT I \\nTwo Stages of ML \\nThe typical machine learning (ML) development process can be broken down into two \\nprimary stages: \\n1. Data Preparation and Model Training: \\no Data Collection and Preparation:  Gathering relevant data, cleaning it, and \\ntransforming it into a suitable format for model training. \\no Model Selection and Training:  Choosing an appropriate ML algorithm and \\ntraining it on the prepared data to learn patterns. \\n2. Model Evaluation and Deployment: \\no Model Evaluation: Assessing the model's performance on a separate dataset to \\nunderstand its accuracy and reliability. \\no Model Deployment:  Integrating the trained model into a production \\nenvironment to make predictions or decisions. \\nML in Google Products \\nGoogle is a pioneer in applying ML to its products. Some prominent examples include: \\n• Search Engine: Understanding search queries, ranking results, and providing relevant \\ninformation.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}, page_content='Google is a pioneer in applying ML to its products. Some prominent examples include: \\n• Search Engine: Understanding search queries, ranking results, and providing relevant \\ninformation. \\n• Google Photos: Image recognition, object detection, and organization based on content. \\n• Google Translate: Real-time language translation using neural machine translation. \\n• Gmail: Spam filtering, smart reply, and priority inbox features. \\n• Google Assistant:  Natural language understanding, speech recognition, and task \\ncompletion. \\n \\nDialogflow \\nDialogflow (formerly known as Api.ai), is the platform owned by Google to build \\nconversational agents.  \\nInstead of building a chatbot from scratch, Dialogflow makes it easier to build it in considerably \\nless time and with bunch of Google features, including pre-build ML Models that can help you \\nget started right away. Dialogflow also allows you to integrate your conversational agent with'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}, page_content='less time and with bunch of Google features, including pre-build ML Models that can help you \\nget started right away. Dialogflow also allows you to integrate your conversational agent with \\npopular platforms like Google Assistant, Facebook Messenger, Twitter, Telegram and more. It \\nalso provides Web API to integrate the agent into Websites. \\nAccessing Dialogflow Console: \\n1) Visit https://dialogflow.com.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}, page_content='2 \\nMachine Learning Operations \\n \\n2) Sign-in using your Google Account and allow the access to Dialogflow.  \\n \\n3) Access the console by clicking Go to console button in the top-right corner.  \\n \\n \\nGetting familiar with Dialogflow Console:  \\n \\n \\nAgents \\nEvery Conversational Chatbot you make using Dialogflow are called  Agents. In the Console \\nyou can see all your agents in the top-left corner where you can configure the agent settings by \\nclicking Gear icon next to your agent name.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3'}, page_content='3 \\nMachine Learning Operations \\n \\nSections in Agent Settings: \\n• General: Here you can configure your Agent name, timezone and delete the agent. \\n• Export/Import: In this section you can backup and restore your Agents  (It is good \\npractice to Export your Agent periodically).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4'}, page_content='4 \\nMachine Learning Operations \\nIntents \\n \\nIntents comprises of what End-User’s intend to say. For every agent, there are intents defined \\nto fulfill End -User’s query. Each intent has a specific purpose. When User types a query, \\nDialogflow matches the particular intent and responds to the User. \\nYou can create an Intent using Create Intent button, or by using the  Plus icon next to Intent \\nin the Console Pane. \\nAfter opening an Intent, you enter the  Training Phrases. These are the example phrases that \\nUser will say. When User’s query resembles these phrases, Dialogflow will match the Intent. \\nYou need to define few phrases and the built-in Machine Learning will add more phrases over \\nthe time. \\n \\nIn the Responses section of Intent, you provide the statement which is used as the reply to the \\nUser’s Invocation Phrase. You can define multiple replies and Dialogflow will randomly \\nprovide a reply from the given responses.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5'}, page_content='5 \\nMachine Learning Operations \\n \\nOther than Training Phrases and Responses, another powerful feature of Dialogflow is Actions \\nand Parameters. In some intents you would like to obtain a particular data from User’s phrase. \\nYou can define parameters by right-clicking any phrase from the Invocation Phrases list, and \\nselect the Entity -type that suits your requirement. Dialogflow has built -in parame ters \\nlike sys.geo-location, sys.date and more. You can even define your own parameters (in the \\nEntities).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6'}, page_content='6 \\nMachine Learning Operations \\nEntities \\nEntities in context of Dialogflow are the set of Keywords that can be extracted as a parameter. \\nYou can define an Entity using  Create Entity or the Plus icon next to Entity in the Console \\nPane. \\nHere, each Entry in the Entity holds a specific keyword. These keywords can have several \\nsynonyms. Dialogflow allows you to define synonyms along with the keyword. \\n \\nFor example, if you define an entity “ GeographicalFeature” with entry “ Water Body” and \\ndefine synonyms as  lake, pond, ocean . When user says “I want to visit  ocean“. Dialogflow \\nunderstands the reference and extracts the parameter as “Water Body”. \\nEntities are really useful. These extracted parameters can be used to make conversations more \\nhuman-like (using Fulfillment). \\nFulfillment \\nUsing Fulfillment adds more functionality to your agent. You have to enable Fulfillment for \\neach Intent you require. There are two way to use the Fulfillment feature: \\n• Webhook'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7'}, page_content='7 \\nMachine Learning Operations \\nUsing Webhook, you can use externally deployed back-end to fulfill user query. The extracted \\nparameter are packed using JSON. In the Webhook section you just need to provide the URL \\nfor your back -end and during each invocation, Dialogflow will send the use r’s query and \\nParameters to the back-end. \\n• Inline Editor \\n \\nInline Editor allows you to manage fulfillment directly from the cloud functions. You need to \\nhave understanding of NodeJS to use Inline Editor. Here you can \\nmodify index.js and package.json according to the requirement of your agent. \\nIntegrations \\nAfter completing your agent, the last part is Integration. Here you can deploy your Agent to \\npopular services like Google Assistant, Facebook Messenger and more. Select the platform to \\ndeploy your agent.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8'}, page_content='8 \\nMachine Learning Operations'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9'}, page_content='9 \\nMachine Learning Operations \\n  \\nVision API \\nThe Vision API is a powerful tool that uses machine learning to understand the content \\nof images. It provides developers with a simple interface to access pre-trained models that can \\nextract information from images. \\nHow it works: \\n1. Image Upload: You send an image to the Vision API, either as an image file or an \\nimage URL. \\n2. Image Analysis:  The API processes the image using advanced machine learning \\nmodels. \\n3. Response: The API returns information about the image, such as labels, detected \\nobjects, or extracted text. \\nKey Features: \\n• Image Labeling: Identifies objects, places, and actions within an image. \\n• Face Detection:  Detects faces within an image and provides information about \\nattributes like emotions, landmarks, and poses. \\n• Optical Character Recognition (OCR):  Extracts printed and handwritten text from \\nimages. \\n• Landmark Detection: Identifies famous landmarks within an image.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9'}, page_content=\"• Optical Character Recognition (OCR):  Extracts printed and handwritten text from \\nimages. \\n• Landmark Detection: Identifies famous landmarks within an image. \\n• Logo Detection: Recognizes logos of popular brands. \\n• Image Properties: Provides information about image properties like dominant colors. \\n• Safe Search Detection: Identifies potentially sensitive content within images. \\n \\nGetting Started \\n1. Enable the Vision API: Visit the Google Cloud Platform console, navigate to the API & \\nServices section, and enable the Vision API for your project. \\n2. Set Up Authentication: Create a service account with appropriate permissions and \\ngenerate a key file. \\n3. Choose a Programming Language: The Vision API supports multiple languages, \\nincluding Python, Java, Node.js, and Go. \\n1. Enabling the Google Cloud Vision API \\nTo use the Google Cloud Vision API, you'll need to enable it for your Google Cloud project. \\nHere's a step-by-step guide:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10'}, page_content='10 \\nMachine Learning Operations \\nPrerequisites: \\n• A Google Cloud Platform (GCP) account. \\n• A Google Cloud project with billing enabled. \\nSteps: \\n1. Sign in to the Google Cloud Console: Visit https://console.cloud.google.com/ and sign \\nin with your Google account. \\n2. Select or Create a Project:  Choose an existing project or create a new one for your \\nVision API usage. \\n3. Enable the Vision API: \\no Navigate to the APIs & Services section in the console. \\no Search for \"Cloud Vision API\" and select it. \\no Click the Enable button. \\n2. Setting Up Authentication for the Google Cloud Vision API \\nTo use the Google Cloud Vision API, you\\'ll need to authenticate your requests. This ensures \\nthat Google can verify your identity and authorize access to the API. \\nUnderstanding Authentication Methods \\nThere are two primary methods for authenticating with the Google Cloud Vision API: \\n1. Application Default Credentials (ADC):  This method is suitable for local'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10'}, page_content='Understanding Authentication Methods \\nThere are two primary methods for authenticating with the Google Cloud Vision API: \\n1. Application Default Credentials (ADC):  This method is suitable for local \\ndevelopment and testing. It automatically uses the credentials associated with your \\nGoogle account. \\n2. Service Accounts: For production environments and more granular control, service \\naccounts provide a robust authentication mechanism. \\nSetting Up Service Accounts \\n1. Create a Service Account: \\no Go to the Google Cloud Console and navigate to the IAM & Admin section. \\no Select \"Service accounts\" and click \"Create Service Account\". \\no Give your service account a name and description. \\no Grant the necessary roles to the service account. For Vision API, the \"Cloud \\nVision API User\" role is sufficient. \\n2. Create a Key: \\no Select the newly created service account and click the \"Keys\" tab. \\no Click \"Add Key\" and choose \"Create new key\".'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10'}, page_content='Vision API User\" role is sufficient. \\n2. Create a Key: \\no Select the newly created service account and click the \"Keys\" tab. \\no Click \"Add Key\" and choose \"Create new key\". \\no Select the JSON key type and download the generated JSON file.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11'}, page_content=\"11 \\nMachine Learning Operations \\n3. Store the Key: \\no Securely store the JSON key file. You'll use this file to authenticate your API \\nrequests. \\n3. How to Choose a Programming Language \\nSelecting the right programming language for a project can be a daunting task. Here are some \\nkey factors to consider: \\nUnderstand Your Project Requirements \\n• Type of application:  Is it a web application, mobile app, desktop software, data \\nanalysis, or something else? \\n• Platform: Where will the application run (web, mobile, desktop, cloud)? \\n• Performance requirements: Are there specific speed or efficiency needs? \\n• Scalability: Will the application need to handle a large amount of data or users? \\n• Security needs: Are there sensitive data or security requirements? \\n• Team expertise: What languages are your team proficient in? \\nEvaluate Language Features \\n• Syntax and readability: How easy is the language to understand and maintain?\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11'}, page_content='• Team expertise: What languages are your team proficient in? \\nEvaluate Language Features \\n• Syntax and readability: How easy is the language to understand and maintain? \\n• Standard library: Does the language offer built-in functions for common tasks? \\n• Ecosystem: Is there a large and active community with libraries and frameworks? \\n• Performance: How fast is the language for different types of tasks? \\n• Cross-platform compatibility: Can the language be used for multiple platforms? \\n• Learning curve: How easy is it to learn the language? \\nPopular Languages and Their Use Cases \\n• Python: Versatile language for data science, machine learning, web development, and \\nscripting. \\n• JavaScript: Primarily used for web development, but also gaining popularity in other \\nareas. \\n• Java: Robust language for enterprise applications, Android app development, and big \\ndata processing. \\n• C++: High-performance language for system programming, game development, and'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11'}, page_content=\"areas. \\n• Java: Robust language for enterprise applications, Android app development, and big \\ndata processing. \\n• C++: High-performance language for system programming, game development, and \\nperformance-critical applications. \\n• C#: Used for Windows applications, game development, and web development with \\n.NET. \\n• Swift: Apple's language for iOS app development.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12'}, page_content='12 \\nMachine Learning Operations \\n• Kotlin: Modern language for Android app development and multiplatform \\ndevelopment. \\n \\n \\nML training phases \\nThe machine learning lifecycle is a process that guides the development and deployment of \\nmachine learning models in a structured way. It consists of various steps. \\nEach step plays a crucial role in ensuring the success and effectiveness of the machine learning \\nsolution. By following the machine learning lifecycle, organizations can solve complex \\nproblems systematically, leverage data -driven insights, and create scala ble and sustainable \\nmachine learning solutions that deliver tangible value. The steps to be followed in the machine \\nlearning lifecycle are: \\n1. Problem Definition \\n2. Data Collection \\n3. Data Cleaning and Preprocessing \\n4. Exploratory Data Analysis (EDA) \\n5. Feature Engineering and Selection \\n6. Model Selection \\n7. Model Training \\n8. Model Evaluation and Tuning \\n9. Model Deployment \\n10. Model Monitoring and Maintenance'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12'}, page_content='5. Feature Engineering and Selection \\n6. Model Selection \\n7. Model Training \\n8. Model Evaluation and Tuning \\n9. Model Deployment \\n10. Model Monitoring and Maintenance \\n \\nMachine Learning Lifecycle'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13'}, page_content='13 \\nMachine Learning Operations \\nStep 1: Problem Definition \\nEmbarking on the machine learning journey involves a well-defined lifecycle, starting with the \\ncrucial step of problem definition. In this initial phase, stakeholders collaborate to identify the \\nbusiness problem at hand and frame it in a way that sets the stage for the entire process. \\nBy framing the problem in a comprehensive manner, the team establishes a foundation for the \\nentire machine learning lifecycle. Crucial elements, such as  project objectives, desired \\noutcomes, and the scope of the task, are carefully delineated during this stage. \\nHere are the basic features of problem definition: \\n• Collaboration: Work together with stakeholders to understand and define the business \\nproblem. \\n• Clarity: Clearly articulate the objectives, desired outcomes, and scope of the task. \\n• Foundation: Establish a solid foundation for the machine learning process by framing \\nthe problem comprehensively. \\nStep 2: Data Collection'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13'}, page_content='• Foundation: Establish a solid foundation for the machine learning process by framing \\nthe problem comprehensively. \\nStep 2: Data Collection \\nFollowing the precision of problem definition, the machine learning lifecycle progresses to the \\npivotal stage of data collection. This phase involves the systematic gathering of datasets that \\nwill serve as the raw material for model development. The qualit y and diversity of the data \\ncollected directly impact the robustness and generalizability of the machine learning model. \\nDuring data collection, practitioners must consider the relevance of the data to the defined \\nproblem, ensuring that the selected datasets encompass the necessary features and \\ncharacteristics. Additionally, factors such as data volume, quality, and ethical considerations \\nplay a crucial role in shaping the foundation for subsequent phases of the machine learning \\nlifecycle. A meticulous and well-organized approach to data collection lays the groundwork for'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13'}, page_content='play a crucial role in shaping the foundation for subsequent phases of the machine learning \\nlifecycle. A meticulous and well-organized approach to data collection lays the groundwork for \\neffective model training, evaluation, and deployment, ensuring that the resulting model is both \\naccurate and applicable to real-world scenarios. \\nHere are the basic features of Data Collection: \\n• Relevance: Collect data that is relevant to the defined problem and includes necessary \\nfeatures. \\n• Quality: Ensure data quality by considering factors like accuracy, completeness, and \\nethical considerations. \\n• Quantity: Gather sufficient data volume to train a robust machine learning model. \\n• Diversity: Include diverse datasets to capture a broad range of scenarios and patterns. \\nStep 3: Data Cleaning and Preprocessing \\nWith datasets in hand, the machine learning journey advances to the critical stages of  data'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13'}, page_content='Step 3: Data Cleaning and Preprocessing \\nWith datasets in hand, the machine learning journey advances to the critical stages of  data \\ncleaning and preprocessing. Raw data, is often messy and unstructured. Data cleaning involves \\naddressing issues such as missing values, outliers, and inconsistencies that could compromise \\nthe accuracy and reliability of the machine learning model.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14'}, page_content='14 \\nMachine Learning Operations \\nPreprocessing takes this a step further by standardizing formats, scaling values, and encoding \\ncategorical variables, creating a consistent and well-organized dataset. The objective is to refine \\nthe raw data into a format that facilitates meaningful analysis during subsequent phases of the \\nmachine learning lifecycle. By investing time and effort in data cleaning and preprocessing, \\npractitioners lay the foundation for robust model development, ensuring that the model is \\ntrained on high-quality, reliable data. \\nHere are the basic features of Data Cleaning and Preprocessing: \\n• Data Cleaning: Address issues such as missing values, outliers, and inconsistencies in \\nthe data. \\n• Data Preprocessing:  Standardize formats, scale values, and encode categorical \\nvariables for consistency. \\n• Data Quality:  Ensure that the data is well -organized and prepared for meaningful \\nanalysis.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14'}, page_content='variables for consistency. \\n• Data Quality:  Ensure that the data is well -organized and prepared for meaningful \\nanalysis. \\n• Data Integrity: Maintain the integrity of the dataset by cleaning and preprocessing it \\neffectively. \\nStep 4: Exploratory Data Analysis (EDA) \\nNow, focus turns to understanding the underlying patterns and characteristics of the collected \\ndata. Exploratory Data Analysis (EDA) emerges as a pivotal phase, where practitioners \\nleverage various statistical and visual tools to gain insights into the dataset’s structure. \\nDuring EDA, patterns, trends, and potential challenges are unearthed, providing valuable \\ncontext for subsequent decisions in the machine learning process. Visualizations, summary \\nstatistics, and correlation analyses offer a comprehensive view of the data, guiding practitioners \\ntoward informed choices in  feature engineering, model selection, and other critical aspects.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14'}, page_content='statistics, and correlation analyses offer a comprehensive view of the data, guiding practitioners \\ntoward informed choices in  feature engineering, model selection, and other critical aspects. \\nEDA acts as a compass, directing the machine learning journey by revealing the intricacies of \\nthe data and informing the development of effective and accurate predictive models. \\nHere are the basic features of Exploratory Data Analysis: \\n• Exploration: Use statistical and visual tools to explore the structure and patterns in the \\ndata. \\n• Patterns and Trends:  Identify underlying patterns, trends, and potential challenges \\nwithin the dataset. \\n• Insights: Gain valuable insights to inform decisions in later stages of the machine \\nlearning process. \\n• Decision Making:  Use exploratory data analysis to make informed decisions about \\nfeature engineering and model selection. \\nStep 5: Feature Engineering and Selection'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14'}, page_content='learning process. \\n• Decision Making:  Use exploratory data analysis to make informed decisions about \\nfeature engineering and model selection. \\nStep 5: Feature Engineering and Selection \\nFeature engineering takes center stage as a transformative process that elevates raw data into \\nmeaningful predictors. Simultaneously,  feature selection  refines this pool of variables, \\nidentifying the most relevant ones to enhance model efficiency and effectiveness.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15'}, page_content='15 \\nMachine Learning Operations \\nFeature engineering involves creating new features or transforming existing ones to better \\ncapture patterns and relationships within the data. This creative process requires domain \\nexpertise and a deep understanding of the problem at hand, ensuring that th e engineered \\nfeatures contribute meaningfully to the predictive power of the model. On the other hand, \\nfeature selection focuses on identifying the subset of features that most significantly impact the \\nmodel’s performance. This dual approach seeks to strik e a delicate balance, optimizing the \\nfeature set for predictive accuracy while minimizing computational complexity. \\nHere are the basic features of Feature Engineering and Selection: \\n• Feature Engineering: Create new features or transform existing ones to better capture \\npatterns and relationships. \\n• Feature Selection: Identify the subset of features that most significantly impact the \\nmodel’s performance.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15'}, page_content='patterns and relationships. \\n• Feature Selection: Identify the subset of features that most significantly impact the \\nmodel’s performance. \\n• Domain Expertise: Leverage domain knowledge to engineer features that contribute \\nmeaningfully to predictive power. \\n• Optimization: Balance feature set for predictive accuracy while minimizing \\ncomputational complexity. \\nStep 6: Model Selection \\nNavigating the machine learning lifecycle requires the judicious selection of a model that aligns \\nwith the defined problem and the characteristics of the dataset. Model selection is a pivotal \\ndecision that determines the algorithmic framework guiding the p redictive capabilities of the \\nmachine learning solution. The choice depends on the nature of the data, the complexity of the \\nproblem, and the desired outcomes. \\nHere are the basic features of Model Selection: \\n• Alignment: Select a model that aligns with the defined problem and characteristics of \\nthe dataset.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15'}, page_content='problem, and the desired outcomes. \\nHere are the basic features of Model Selection: \\n• Alignment: Select a model that aligns with the defined problem and characteristics of \\nthe dataset. \\n• Complexity: Consider the complexity of the problem and the nature of the data when \\nchoosing a model. \\n• Decision Factors: Evaluate factors like performance, interpretability, and scalability \\nwhen selecting a model. \\n• Experimentation: Experiment with different models to find the best fit for the problem \\nat hand. \\nStep 7: Model Training \\nWith the selected model in place, the machine learning lifecycle advances to the transformative \\nphase of model training. This process involves exposing the model to historical data, allowing \\nit to learn patterns, relationships, and dependencies within the dataset. \\nModel training is an iterative and dynamic journey, where the algorithm adjusts its parameters \\nto minimize errors and enhance predictive accuracy. During this phase, the model fine -tunes'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15'}, page_content='Model training is an iterative and dynamic journey, where the algorithm adjusts its parameters \\nto minimize errors and enhance predictive accuracy. During this phase, the model fine -tunes \\nits understanding of the data, optimizing its ability to make meaning ful predictions. Rigorous'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='16 \\nMachine Learning Operations \\nvalidation processes ensure that the trained model generalizes well to new, unseen data, \\nestablishing a foundation for reliable predictions in real-world scenarios. \\nHere are the basic features of Model Training: \\n• Training Data: Expose the model to historical data to learn patterns, relationships, and \\ndependencies. \\n• Iterative Process: Train the model iteratively, adjusting parameters to minimize errors \\nand enhance accuracy. \\n• Optimization: Fine-tune the model’s understanding of the data to optimize predictive \\ncapabilities. \\n• Validation: Rigorously validate the trained model to ensure generalization to new, \\nunseen data. \\nStep 8: Model Evaluation and Tuning \\nModel evaluation involves rigorous testing against validation datasets, employing metrics such \\nas accuracy, precision, recall, and F1 score to gauge its effectiveness. \\nEvaluation is a critical checkpoint, providing insights into the model’s strengths and'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='as accuracy, precision, recall, and F1 score to gauge its effectiveness. \\nEvaluation is a critical checkpoint, providing insights into the model’s strengths and \\nweaknesses. If the model falls short of desired performance levels, practitioners initiate model \\ntuning—a process that involves adjusting hyperparameters to enhance pred ictive accuracy. \\nThis iterative cycle of evaluation and tuning is crucial for achieving the desired level of model \\nrobustness and reliability. \\nHere are the basic features of Model Evaluation and Tuning: \\n• Evaluation Metrics:  Use metrics like accuracy, precision, recall, and F1 score to \\nevaluate model performance. \\n• Strengths and Weaknesses:  Identify the strengths and weaknesses of the model \\nthrough rigorous testing. \\n• Iterative Improvement: Initiate model tuning to adjust hyperparameters and enhance \\npredictive accuracy. \\n• Model Robustness:  Iterate through evaluation and tuning cycles to achieve desired'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='• Iterative Improvement: Initiate model tuning to adjust hyperparameters and enhance \\npredictive accuracy. \\n• Model Robustness:  Iterate through evaluation and tuning cycles to achieve desired \\nlevels of model robustness and reliability. \\nStep 9: Model Deployment \\nUpon successful evaluation, the machine learning model transitions from development to real-\\nworld application through the deployment phase. Model deployment involves integrating the \\npredictive solution into existing systems or processes, allowing stakehold ers to leverage its \\ninsights for informed decision-making. \\nModel deployment marks the culmination of the machine learning lifecycle, transforming \\ntheoretical insights into practical solutions that drive tangible value for organizations. \\nHere are the basic features of Model Deployment:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content=\"17 \\nMachine Learning Operations \\n• Integration: Integrate the trained model into existing systems or processes for real -\\nworld application. \\n• Decision Making: Use the model’s predictions to inform decision -making and drive \\ntangible value for organizations. \\n• Practical Solutions: Deploy the model to transform theoretical insights into practical \\nsolutions that address business needs. \\n• Continuous Improvement:  Monitor model performance and make adjustments as \\nnecessary to maintain effectiveness over time. \\n \\nAI Platform notebooks (Tour) \\nAI Platform Notebooks on Google Cloud provide an easy and powerful environment for data \\nscientists to create and manage machine learning (ML) projects. Here's a simple explanation \\nwith examples: \\nManaged Jupyter Notebooks: \\n• Explanation: These notebooks are enhanced versions of standard Jupyter notebooks. \\nGoogle Cloud manages the servers, so you don't have to worry about setting them up.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content=\"Managed Jupyter Notebooks: \\n• Explanation: These notebooks are enhanced versions of standard Jupyter notebooks. \\nGoogle Cloud manages the servers, so you don't have to worry about setting them up. \\n• Example: You can run Python code to analyze data or train a machine learning model \\nusing TensorFlow, without having to install anything on your computer. Just open your \\nbrowser, and everything is ready for you. \\nCollaboration and Version Control: \\n• Explanation: AI Platform Notebooks integrate with Git, allowing you to track changes \\nand collaborate with others easily. \\n• Example: If you make a mistake in your code, you can use Git to revert to an earlier \\nversion. You can also work on the same project with your team, seeing each other's \\nchanges in real time. \\nCustomizable Hardware Profiles: \\n• Explanation: You can choose the type of hardware you need for your project, whether \\nit's a powerful GPU for deep learning or just a CPU for data analysis.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content=\"Customizable Hardware Profiles: \\n• Explanation: You can choose the type of hardware you need for your project, whether \\nit's a powerful GPU for deep learning or just a CPU for data analysis. \\n• Example: If you're training a complex neural network, you might select a GPU to speed \\nup the process. For simple tasks like data cleaning, you can stick with a basic CPU to \\nsave costs. \\nIntegrated with Google Cloud Services: \\n• Explanation: The notebooks can connect to other Google Cloud services like \\nBigQuery and Cloud Storage, making it easy to access and analyze large datasets. \\n• Example: You can query large datasets in BigQuery directly from your notebook and \\nvisualize the results with Matplotlib, all without leaving the notebook environment.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content=\"18 \\nMachine Learning Operations \\nHow to Get Started? \\n1. Create Your Notebook Instance: \\no Explanation: Use the Google Cloud Console to set up a new notebook \\nenvironment. \\no Example: Choose a notebook template with TensorFlow pre-installed if you're \\nplanning to build a neural network. \\n2. Write Some Code: \\no Explanation: Open your notebook and start coding. You can do everything \\nfrom data preprocessing to model training and visualization. \\no Example: Write Python code to load your dataset, train a machine learning \\nmodel, and plot the results using libraries like Pandas and Matplotlib. \\n3. Collaborate and Share: \\no Explanation: Share your notebook with colleagues to work together on the \\nproject. \\no Example: Invite your team to review your code, discuss the results, and make \\nimprovements collaboratively. \\n4. Debugging and Exploration: \\no Explanation: Use tools like the What -If Tool to understand how your model \\nworks and find any issues.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content=\"improvements collaboratively. \\n4. Debugging and Exploration: \\no Explanation: Use tools like the What -If Tool to understand how your model \\nworks and find any issues. \\no Example: Visualize how changes in input data affect your model's predictions, \\nhelping you improve its accuracy. \\nWhy Should You Care? \\n• Productivity Boost:  No need to worry about installing software or dealing with \\ndependencies. The environment is always ready for you. \\n• Scalability and Flexibility: Easily adjust the resources you need, scaling up or down \\nas required by your project. \\n• Data Science Nirvana:  Focus on analyzing data and building models, while Google \\nCloud takes care of the infrastructure. You can even deploy your models directly from \\nthe notebook. \\n \\nDevelopment process – Computations and Storage \\nThe development process for AI Platform Notebooks involves several key stages, focusing on \\ncomputations and storage. Here's a simple breakdown: \\nDevelopment Process: Computations and Storage\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content=\"The development process for AI Platform Notebooks involves several key stages, focusing on \\ncomputations and storage. Here's a simple breakdown: \\nDevelopment Process: Computations and Storage \\n1. Setting Up the Environment:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19'}, page_content='19 \\nMachine Learning Operations \\n• Compute Resources: \\no Explanation: Choose the appropriate hardware for your project needs, such as \\nCPUs, GPUs, or TPUs. \\no Example: For training a large deep learning model, you might opt for a GPU to \\naccelerate computations. \\n• Storage Options: \\no Explanation: Decide on the storage capacity required for your data and models. \\no Example: Use Google Cloud Storage for large datasets or to save model \\ncheckpoints during training. \\n2. Data Management: \\n• Data Ingestion: \\no Explanation: Import data from various sources into your notebook \\nenvironment. \\no Example: Load data from a CSV file stored in Google Cloud Storage or query \\na dataset from BigQuery. \\n• Data Preprocessing: \\no Explanation: Clean and prepare data for analysis and model training. \\no Example: Use Pandas to handle missing values and normalize data. \\n3. Model Development: \\n• Building Models: \\no Explanation: Write and test code to create machine learning models using'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19'}, page_content='o Example: Use Pandas to handle missing values and normalize data. \\n3. Model Development: \\n• Building Models: \\no Explanation: Write and test code to create machine learning models using \\nlibraries like TensorFlow, PyTorch, or Scikit-learn. \\no Example: Develop a neural network for image classification using TensorFlow. \\n• Training Models: \\no Explanation: Use the chosen compute resources to train models on your \\ndataset. \\no Example: Train a model on a GPU to reduce training time for a complex neural \\nnetwork. \\n• Hyperparameter Tuning: \\no Explanation: Optimize model performance by adjusting hyperparameters. \\no Example: Use grid search or random search to find the best combination of \\nlearning rate and batch size. \\n4. Evaluation and Debugging: \\n• Model Evaluation:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20'}, page_content='20 \\nMachine Learning Operations \\no Explanation: Assess model performance using appropriate metrics and \\nvalidation data. \\no Example: Calculate accuracy, precision, and recall for a classification model. \\n• Debugging: \\no Explanation: Identify and fix issues in your code or model. \\no Example: Use the What-If Tool to analyze model predictions and understand \\nerrors. \\n5. Collaboration and Version Control: \\n• Collaboration: \\no Explanation: Work with team members to improve and refine models. \\no Example: Share notebooks via Google Cloud and use comments to discuss \\ncode changes. \\n• Version Control: \\no Explanation: Use Git to track changes and maintain versions of your notebook. \\no Example: Revert to a previous version if a recent change caused an issue. \\n6. Deployment: \\n• Model Deployment: \\no Explanation: Transition models from development to production \\nenvironments. \\no Example: Deploy a trained model using AI Platform Predictions to serve \\npredictions via an API. \\n• Monitoring:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-08-14T23:46:40+05:30', 'author': 'Dr Selvam L', 'moddate': '2025-08-18T07:12:05+05:30', 'source': '..\\\\data\\\\pdf\\\\unit1.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20'}, page_content='o Explanation: Transition models from development to production \\nenvironments. \\no Example: Deploy a trained model using AI Platform Predictions to serve \\npredictions via an API. \\n• Monitoring: \\no Explanation: Continuously monitor model performance in production. \\no Example: Set up alerts to track model accuracy and latency.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0aa16ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EmbeddingManager' object has no attribute 'generate_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m texts=[doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m## Generate the Embeddings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m embeddings=\u001b[43membedding_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_embeddings\u001b[49m(texts)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m##store int he vector dtaabase\u001b[39;00m\n\u001b[32m      9\u001b[39m vectorstore.add_documents(chunks,embeddings)\n",
      "\u001b[31mAttributeError\u001b[39m: 'EmbeddingManager' object has no attribute 'generate_embeddings'"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the Embeddings\n",
    "\n",
    "embeddings=embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "##store int he vector dtaabase\n",
    "vectorstore.add_documents(chunks,embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a735758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Experiments_RaG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
